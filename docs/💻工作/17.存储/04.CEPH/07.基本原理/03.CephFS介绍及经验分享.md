---
title: CEPHFS ä»‹ç»åŠç»éªŒåˆ†äº«

categories: 
  - ğŸ’»å·¥ä½œ
  - å­˜å‚¨
  - CEPH
  - åŸºæœ¬åŸç†
tags: 
  - CEPH
date: 2020-05-23 11:02:28
permalink: /pages/62b7ce/
---

![image.png](https://upload-images.jianshu.io/upload_images/2099201-c8191260b9465f8f.png)

Ceph æ˜¯ä¸€ç§ä¸ºä¼˜ç§€çš„æ€§èƒ½ã€å¯é æ€§å’Œå¯æ‰©å±•æ€§è€Œè®¾è®¡çš„ç»Ÿä¸€çš„ã€åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿã€‚

**ç‰¹ç‚¹å¦‚ä¸‹ï¼š**
- é«˜æ€§èƒ½
  - æ‘’å¼ƒäº†ä¼ ç»Ÿçš„é›†ä¸­å¼å­˜å‚¨å…ƒæ•°æ®å¯»å€çš„æ–¹æ¡ˆï¼Œé‡‡ç”¨ CRUSH ç®—æ³•ï¼Œæ•°æ®åˆ†å¸ƒå‡è¡¡ï¼Œå¹¶è¡Œåº¦é«˜ï¼›
  - è€ƒè™‘äº†å®¹ç¾åŸŸçš„éš”ç¦»ï¼Œèƒ½å¤Ÿå®ç°å„ç±»è´Ÿè½½çš„å‰¯æœ¬æ”¾ç½®è§„åˆ™ï¼Œä¾‹å¦‚è·¨æœºæˆ¿ã€æœºæ¶æ„ŸçŸ¥ç­‰ï¼›
  -  èƒ½å¤Ÿæ”¯æŒä¸Šåƒä¸ªå­˜å‚¨èŠ‚ç‚¹çš„è§„æ¨¡ï¼Œæ”¯æŒ TB åˆ° PB çº§çš„æ•°æ®ï¼›
- é«˜å¯ç”¨æ€§
  - å‰¯æœ¬æ•°å¯ä»¥çµæ´»æ§åˆ¶ï¼›
  - æ”¯æŒæ•…éšœåŸŸåˆ†éš”ï¼Œæ•°æ®å¼ºä¸€è‡´æ€§ï¼›
  - å¤šç§æ•…éšœåœºæ™¯è‡ªåŠ¨è¿›è¡Œä¿®å¤è‡ªæ„ˆï¼›
  - æ²¡æœ‰å•ç‚¹æ•…éšœï¼Œè‡ªåŠ¨ç®¡ç†ï¼›
- é«˜å¯æ‰©å±•æ€§
  - å»ä¸­å¿ƒåŒ–ï¼›
  - æ‰©å±•çµæ´»ï¼›
  - éšç€èŠ‚ç‚¹å¢åŠ è€Œçº¿æ€§å¢é•¿ï¼›
- ç‰¹æ€§ä¸°å¯Œ
  - æ”¯æŒä¸‰ç§å­˜å‚¨æ¥å£ï¼šå—å­˜å‚¨ã€æ–‡ä»¶å­˜å‚¨ã€å¯¹è±¡å­˜å‚¨ï¼›
  - æ”¯æŒè‡ªå®šä¹‰æ¥å£ï¼Œæ”¯æŒå¤šç§è¯­è¨€é©±åŠ¨ï¼›

**ä½¿ç”¨åœºæ™¯ï¼š**

 - **å—å­˜å‚¨** (é€‚åˆå•å®¢æˆ·ç«¯ä½¿ç”¨)
    - å…¸å‹è®¾å¤‡ï¼šç£ç›˜é˜µåˆ—ï¼Œç¡¬ç›˜ï¼›
    - ä½¿ç”¨åœºæ™¯ï¼š
        - a. docker å®¹å™¨ã€è™šæ‹Ÿæœºè¿œç¨‹æŒ‚è½½ç£ç›˜å­˜å‚¨åˆ†é…ï¼›
        - b. æ—¥å¿—å­˜å‚¨ï¼›
        - ...
 - **æ–‡ä»¶å­˜å‚¨** (é€‚åˆå¤šå®¢æˆ·ç«¯æœ‰ç›®å½•ç»“æ„)
    - å…¸å‹è®¾å¤‡ï¼šFTPã€NFS æœåŠ¡å™¨ï¼›
    - ä½¿ç”¨åœºæ™¯ï¼š
        - a. æ—¥å¿—å­˜å‚¨ï¼›
        - b. å¤šä¸ªç”¨æˆ·æœ‰ç›®å½•ç»“æ„çš„æ–‡ä»¶å­˜å‚¨å…±äº«ï¼›
        - ...
 - **å¯¹è±¡å­˜å‚¨** (é€‚åˆæ›´æ–°å˜åŠ¨è¾ƒå°‘çš„æ•°æ®ï¼Œæ²¡æœ‰ç›®å½•ç»“æ„ï¼Œä¸èƒ½ç›´æ¥æ‰“å¼€/ä¿®æ”¹æ–‡ä»¶)
     - å…¸å‹è®¾å¤‡ï¼šs3, swiftï¼›
     - ä½¿ç”¨åœºæ™¯ï¼š
        - a. å›¾ç‰‡å­˜å‚¨ï¼›
        - b. è§†é¢‘å­˜å‚¨ï¼›
        - c. æ–‡ä»¶ï¼›
        - d. è½¯ä»¶å®‰è£…åŒ…ï¼›
        - e. å½’æ¡£æ•°æ®ï¼›
        - ...

**ç³»ç»Ÿæ¶æ„ï¼š**

Ceph ç”Ÿæ€ç³»ç»Ÿæ¶æ„å¯ä»¥åˆ’åˆ†ä¸ºå››éƒ¨åˆ†ï¼š

1. Clientsï¼šå®¢æˆ·ç«¯ï¼ˆæ•°æ®ç”¨æˆ·ï¼‰ï¼›
2. mdsï¼šMetadata server clusterï¼Œå…ƒæ•°æ®æœåŠ¡å™¨ï¼ˆç¼“å­˜å’ŒåŒæ­¥åˆ†å¸ƒå¼å…ƒæ•°æ®ï¼‰ï¼›
3. osdï¼šObject storage clusterï¼Œå¯¹è±¡å­˜å‚¨é›†ç¾¤ï¼ˆå°†æ•°æ®å’Œå…ƒæ•°æ®ä½œä¸ºå¯¹è±¡å­˜å‚¨ï¼Œæ‰§è¡Œå…¶ä»–å…³é”®èŒèƒ½ï¼‰ï¼›
4. monï¼šCluster monitorsï¼Œé›†ç¾¤ç›‘è§†å™¨ï¼ˆæ‰§è¡Œç›‘è§†åŠŸèƒ½ï¼‰ï¼›

![image.png](https://upload-images.jianshu.io/upload_images/2099201-2d5feca9f76485d2.png)


# 2. NFS ä»‹ç»

**1. NAS(Network Attached Storage)**
 - ç½‘ç»œå­˜å‚¨åŸºäºæ ‡å‡†ç½‘ç»œåè®® NFSv3/NFSv4 å®ç°æ•°æ®ä¼ è¾“ï¼›
 - ä¸ºç½‘ç»œä¸­çš„ Windows / Linux / Mac OS ç­‰å„ç§ä¸åŒæ“ä½œç³»ç»Ÿçš„è®¡ç®—æœºæä¾›æ–‡ä»¶å…±äº«å’Œæ•°æ®å¤‡ä»½ï¼›
 - ç›®å‰å¸‚åœºä¸Šçš„ NAS å­˜å‚¨æ˜¯ä¸“é—¨çš„è®¾å¤‡ï¼Œæˆæœ¬è¾ƒé«˜ï¼Œä¸”å®¹é‡ä¸æ˜“åŠ¨æ€æ‰©å±•ï¼Œæ•°æ®é«˜å¯ç”¨éœ€è¦åº•å±‚ RAID æ¥ä¿éšœï¼›
 - CephFS å±äº NAS çš„è§£å†³æ–¹æ¡ˆçš„ä¸€ç§ï¼Œä¸»è¦ä¼˜åŠ¿åœ¨æˆæœ¬ï¼Œå®¹é‡æ‰©å±•å’Œé«˜æ€§èƒ½æ–¹æ¡ˆï¼›

**2. NFS(Network File System)**

 - NFS å³ç½‘ç»œæ–‡ä»¶ç³»ç»Ÿï¼Œé€šè¿‡ä½¿ç”¨ NFSï¼Œç”¨æˆ·å’Œç¨‹åºå¯ä»¥åƒè®¿é—®æœ¬åœ°æ–‡ä»¶ä¸€æ ·è®¿é—®è¿œç«¯ç³»ç»Ÿä¸Šçš„æ–‡ä»¶ï¼›
 - NFS å®¢æˆ·ç«¯å’Œ NFS æœåŠ¡å™¨ä¹‹é—´æ­£æ˜¯é€šè¿‡ NFS åè®®è¿›è¡Œé€šä¿¡çš„ï¼›
 - ç›®å‰ NFS åè®®ç‰ˆæœ¬æœ‰ NFSv3ã€NFSv4 å’Œ NFSv4.1ï¼ŒNFSv3 æ˜¯æ— çŠ¶æ€çš„ï¼ŒNFSv4 æ˜¯æœ‰çŠ¶æ€ï¼ŒNFSv3 å’Œ NFSv4 æ˜¯åŸºäº Filelayout é©±åŠ¨çš„ï¼Œè€Œ NFSv4.1 æ˜¯åŸºäº Blocklayout é©±åŠ¨ã€‚æœ¬æ–‡ä¸»è¦ä½¿ç”¨ NFSv4 åè®®ï¼›

# 3. åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿæ¯”è¾ƒ
| åç§° | åŠŸèƒ½  | é€‚åˆåœºæ™¯ | ä¼˜ç¼ºç‚¹ |
|:---:|:---|:---|:---|
| MFS | 1. å•ç‚¹ MDS<br/> 2. æ”¯æŒ FUSE<br/>3. æ•°æ®åˆ†ç‰‡åˆ†å¸ƒ<br/>4. å¤šå‰¯æœ¬<br/>5. æ•…éšœæ‰‹åŠ¨æ¢å¤| å¤§é‡å°æ–‡ä»¶è¯»å†™| 1. è¿ç»´å®æ–½ç®€å•<br/> 2. ä½†å­˜åœ¨å•ç‚¹æ•…éšœ |
| Ceph | 1. å¤šä¸ª MDS,å¯æ‰©å±•<br/> 2. æ”¯æŒ FUSE<br/>3. æ•°æ®åˆ†ç‰‡(crush)åˆ†å¸ƒ<br/>4. å¤šå‰¯æœ¬/çº åˆ ç <br/>5. æ•…éšœè‡ªåŠ¨æ¢å¤ | ç»Ÿä¸€å°æ–‡ä»¶å­˜å‚¨ | 1. è¿ç»´å®æ–½ç®€å• <br/>2. æ•…éšœè‡ªæ„ˆï¼Œè‡ªæˆ‘æ¢å¤<br/>3. MDS é”çš„é—®é¢˜<br/>4. J ç‰ˆæœ¬å¾ˆå¤šå‘, L ç‰ˆæœ¬å¯ä»¥ä¸Šç”Ÿäº§ç¯å¢ƒ |
| ClusterFS | 1. ä¸å­˜åœ¨å…ƒæ•°æ®èŠ‚ç‚¹<br/> 2. æ”¯æŒ FUSE<br/>3. æ•°æ®åˆ†ç‰‡åˆ†å¸ƒ<br/>4. é•œåƒ<br/> 5. æ•…éšœè‡ªåŠ¨æ¢å¤ | é€‚åˆå¤§æ–‡ä»¶ | 1. è¿ç»´å®æ–½ç®€å•<br/> 2. ä¸å­˜å‚¨å…ƒæ•°æ®ç®¡ç† <br/> 3. å¢åŠ äº†å®¢æˆ·ç«¯è®¡ç®—è´Ÿè½½ |
| Lustre | 1. åŒ MDS äº’å¤‡ï¼Œä¸å¯ç”¨æ‰©å±•<br/>  2. æ”¯æŒ FUSE<br/>3. æ•°æ®åˆ†ç‰‡åˆ†å¸ƒ<br/>4. å†—ä½™(æ— )<br/>5. æ•…éšœè‡ªåŠ¨æ¢å¤ | å¤§æ–‡ä»¶è¯»å†™ | 1. è¿ç»´å®æ–½å¤æ‚ <br/> 2. å¤ªåºå¤§<br/> 3. æ¯”è¾ƒæˆç†Ÿ |

# 4. CephFS ä»‹ç»
![image.png](https://upload-images.jianshu.io/upload_images/2099201-73fd71fa40dcf13b.png)

**è¯´æ˜ï¼š**

 - CephFS æ˜¯ä¸ POSIX æ ‡å‡†å…¼å®¹çš„æ–‡ä»¶ç³»ç»Ÿ
 - æ–‡ä»¶ç›®å½•å’Œå…¶ä»–å…ƒæ•°æ®å­˜å‚¨åœ¨ RADOS ä¸­
 - MDS ç¼“å­˜å…ƒä¿¡æ¯å’Œæ–‡ä»¶ç›®å½•ä¿¡æ¯
 - æ ¸å¿ƒç»„ä»¶ï¼šMDSã€Clientsã€RADOS
      - Client <â€“> MDS
        å…ƒæ•°æ®æ“ä½œå’Œ capalities
      - Client <â€“> OSD
        æ•°æ® IO
      - MDS <â€“> OSD
        å…ƒæ•°æ® IO
 - æŒ‚è½½æ–¹å¼ï¼š
   - ceph-fuse ...
   - mount -t ceph ...
 - å¯æ‰©å±•æ€§
    - client è¯»å†™ osd ï¼›
 - å…±äº«æ–‡ä»¶ç³»ç»Ÿ
    - å¤šä¸ª clients å¯ä»¥åŒæ—¶è¯»å†™ ï¼›
  - é«˜å¯ç”¨
    - MDS ä¸»å¤‡æ¨¡å¼ï¼ŒActive/Standby MDSs ï¼›
 - æ–‡ä»¶/ç›®å½• Layouts
     - æ”¯æŒé…ç½®æ–‡ä»¶/ç›®å½•çš„ Layouts ä½¿ç”¨ä¸åŒçš„ Ppool ï¼›
 - POSIX ACLs
    - CephFS kernel client é»˜è®¤æ”¯æŒï¼›
    - CephFS FUSE client å¯é…ç½®æ”¯æŒ ï¼›
 - NFS-Ganesha
   - ä¸€ä¸ªåŸºäº NFSv3\v4\v4.1 çš„ NFS æœåŠ¡å™¨ï¼›
   - è¿è¡Œåœ¨å¤§å¤šæ•° Linux å‘è¡Œç‰ˆçš„ç”¨æˆ·æ€ç©ºé—´ä¸‹ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒ 9p.2000L åè®®ï¼›
   - Ganesha é€šè¿‡åˆ©ç”¨ libcephfs åº“æ”¯æŒ CephFS FSAL(File System Abstraction Layerï¼Œæ–‡ä»¶ç³»ç»ŸæŠ½è±¡å±‚)ï¼Œå¯ä»¥å°† CephFS é‡æ–° Export å‡ºå»ï¼›
 - Client Quotas
    - CephFS FUSE client æ”¯æŒé…ç½®ä»»ä½•ç›®å½•çš„ Quotasï¼›
 - è´Ÿè½½å‡è¡¡
    - åŠ¨æ€è´Ÿè½½å‡è¡¡ï¼›
    - é™æ€è´Ÿè½½å‡è¡¡ï¼›
    - hash è´Ÿè½½å‡è¡¡ï¼›

# 5. MDS ä»‹ç»
## 5.1 å•æ´» MDS ä»‹ç»
![image.png](https://upload-images.jianshu.io/upload_images/2099201-f64f9c172b44742e.png)

**è¯´æ˜ï¼š**
 - MDS å…¨ç§° Ceph Metadata Serverï¼Œæ˜¯ CephFS æœåŠ¡ä¾èµ–çš„å…ƒæ•°æ®æœåŠ¡ï¼›
 - å…ƒæ•°æ®çš„å†…å­˜ç¼“å­˜ï¼Œä¸ºäº†åŠ å¿«å…ƒæ•°æ®çš„è®¿é—®ï¼›
 - ä¿å­˜äº†æ–‡ä»¶ç³»ç»Ÿçš„å…ƒæ•°æ®(å¯¹è±¡é‡Œä¿å­˜äº†å­ç›®å½•å’Œå­æ–‡ä»¶çš„åç§°å’Œ inode ç¼–å·)ï¼›
 - ä¿å­˜ cephfs æ—¥å¿— journalï¼Œæ—¥å¿—æ˜¯ç”¨æ¥æ¢å¤ mds é‡Œçš„å…ƒæ•°æ®ç¼“å­˜ï¼›
 - é‡å¯ mds çš„æ—¶å€™ä¼šé€šè¿‡ replay çš„æ–¹å¼ä» osd ä¸ŠåŠ è½½ä¹‹å‰ç¼“å­˜çš„å…ƒæ•°æ®ï¼›
 - å¯¹å¤–æä¾›æœåŠ¡åªæœ‰ä¸€ä¸ª active mdsï¼›
 - æ‰€æœ‰ç”¨æˆ·çš„è¯·æ±‚éƒ½åªè½åœ¨ä¸€ä¸ª active mds ä¸Šï¼›

## 5.2 å•æ´» MDS é«˜å¯ç”¨
![image.png](https://upload-images.jianshu.io/upload_images/2099201-7da677e8f2703e6f.png)

**è¯´æ˜ï¼š**
 - å¯¹å¤–æä¾›æœåŠ¡åªæœ‰ä¸€ä¸ª active mds, å¤šä¸ª standby mds
 - active mds æŒ‚æ‰ï¼Œstandby mds ä¼šç«‹é©¬æ¥æ›¿ï¼Œä¿è¯é›†ç¾¤é«˜å¯ç”¨æ€§
 - standby mds
    - å†·å¤‡å°±æ˜¯å¤‡ä»½çš„ mdsï¼Œåªèµ·åˆ°ä¸€ä¸ªè¿›ç¨‹å¤‡ä»½çš„ä½œç”¨ï¼Œå¹¶ä¸å¤‡ä»½ lru å…ƒæ•°æ®ï¼›ä¸»å¤‡è¿›ç¨‹ä¿æŒå¿ƒè·³å…³ç³»ï¼Œä¸€æ—¦ä¸»çš„ mds æŒ‚äº†ï¼Œå¤‡ä»½ mds replay()å…ƒæ•°æ®åˆ°ç¼“å­˜ï¼Œå½“ç„¶è¿™éœ€è¦æ¶ˆè€—ä¸€ç‚¹æ—¶é—´ï¼›
   - çƒ­å¤‡é™¤äº†è¿›ç¨‹å¤‡ä»½ï¼Œå…ƒæ•°æ®ç¼“å­˜è¿˜æ—¶æ—¶åˆ»åˆ»çš„ä¸ä¸» mds ä¿æŒåŒæ­¥ï¼Œå½“ active mds æŒ‚æ‰åï¼Œçƒ­å¤‡çš„ mds ç›´æ¥å˜æˆä¸» mdsï¼Œå¹¶ä¸”æ²¡æœ‰ replay()çš„æ“ä½œï¼Œå…ƒæ•°æ®ç¼“å­˜å¤§å°å’Œä¸» mds ä¿æŒä¸€è‡´ï¼›

# 6. CephFS é‡åˆ°çš„éƒ¨åˆ†é—®é¢˜
## 6.1 å®¢æˆ·ç«¯ç¼“å­˜é—®é¢˜
**æ¶ˆæ¯ï¼š** Client name failing to respond to cache pressure

**è¯´æ˜ï¼š** å®¢æˆ·ç«¯æœ‰å„è‡ªçš„å…ƒæ•°æ®ç¼“å­˜ï¼Œå®¢æˆ·ç«¯ç¼“å­˜ä¸­çš„æ¡ç›®ï¼ˆæ¯”å¦‚ç´¢å¼•èŠ‚ç‚¹ï¼‰ä¹Ÿä¼šå­˜åœ¨äº MDS ç¼“å­˜ä¸­ï¼Œ
æ‰€ä»¥å½“ MDS éœ€è¦å‰Šå‡å…¶ç¼“å­˜æ—¶ï¼ˆä¿æŒåœ¨ mds_cache_size ä»¥ä¸‹ï¼‰ï¼Œå®ƒä¹Ÿä¼šå‘æ¶ˆæ¯ç»™å®¢æˆ·ç«¯è®©å®ƒä»¬å‰Šå‡è‡ªå·±çš„ç¼“å­˜ï¼›å¦‚æœæŸä¸ªå®¢æˆ·ç«¯çš„å“åº”æ—¶é—´è¶…è¿‡äº† mds_recall_state_timeout ï¼ˆé»˜è®¤ä¸º 60s ï¼‰ï¼Œè¿™æ¡æ¶ˆæ¯å°±ä¼šå‡ºç°ï¼›

## 6.2 æœåŠ¡ç«¯ç¼“å­˜ä¸é‡Šæ”¾
å¦‚æœæœ‰å®¢æˆ·ç«¯æ²¡å“åº”æˆ–è€…æœ‰ç¼ºé™·ï¼Œå°±ä¼šå¦¨ç¢ MDS å°†ç¼“å­˜ä¿æŒåœ¨ mds_cache_size ä»¥ä¸‹ï¼Œ MDS å°±æœ‰å¯èƒ½è€—å°½å†…å­˜è€Œåå´©æºƒï¼›

## 6.3 å®¢æˆ·ç«¯å¤¯ä½æˆ–è€…æ…¢æŸ¥è¯¢
 - å®¢æˆ·ç«¯æœç´¢éå†æŸ¥æ‰¾æ–‡ä»¶ï¼ˆä¸å¯æ§ï¼‰ï¼›
 - session çš„ inode å¤ªå¤§å¯¼è‡´ mds è´Ÿè½½è¿‡é«˜ï¼›
 - æ—¥å¿—çº§åˆ«å¼€çš„å¤ªå¤§ï¼Œä»è€Œå¯¼è‡´ mds è´Ÿè½½é«˜ï¼›
 - mds é”é—®é¢˜ï¼Œå¯¼è‡´å®¢æˆ·ç«¯ hang ä½ï¼›
 - mds æ€§èƒ½æœ‰é™ï¼Œç›®å‰æ˜¯å•æ´»ï¼›

## 6.4 å®¢æˆ·ç«¯å¤±å»è¿æ¥
å®¢æˆ·ç«¯ç”±äºç½‘ç»œé—®é¢˜æˆ–è€…å…¶ä»–é—®é¢˜ï¼Œå¯¼è‡´å®¢æˆ·ç«¯ä¸å¯ç”¨ï¼›

## 6.5 ä¸»ä»åˆ‡æ¢é—®é¢˜
 - ä¸»ä»åˆ‡æ¢è€—æ—¶é•¿ï¼›
 - ä¸»ä»åˆ‡æ¢å¾ªç¯é€‰ä¸¾ï¼›

# 7. CephFS é—®é¢˜è§£å†³æ–¹æ¡ˆ

## 7.1 æœåŠ¡ç«¯ç¼“å­˜è­¦å‘Šé—®é¢˜
**v12Â luminous ç‰ˆæœ¬å·²ä¿®å¤ï¼š**
**[https://github.com/ceph/ceph/commit/51c926a74e5ef478c11ccbcf11c351aa520dde2a](https://github.com/ceph/ceph/commit/51c926a74e5ef478c11ccbcf11c351aa520dde2a)**
mds: fix false "failing to respond to cache pressure" warning
- MDS has cache pressure, sends recall state messages to clients
- Client does not trim as many caps as MDS expected. So MDS
  does not reset session->recalled_at
- MDS no longer has cache pressure, it stop sending recall state
  messages to clients.
- Client does not release its caps. So session->recalled_at in
  MDS keeps unchanged

## 7.2 å®¢æˆ·ç«¯ hang ä½é—®é¢˜
### 7.2.1 MDS é”çš„é—®é¢˜
#### 7.2.1.1 åœºæ™¯æ¨¡æ‹Ÿ
 - A ç”¨æˆ·ä»¥åªè¯»çš„æ–¹å¼æ‰“å¼€æ–‡ä»¶ï¼Œä¸å…³é—­æ–‡ä»¶å¥æŸ„ï¼›ç„¶åæ„å¤–æ‰çº¿æˆ–è€…æ‰ç”µï¼ŒB ç”¨æˆ·è¯»å†™è¿™ä¸ªæ–‡ä»¶å°±ä¼š hang ä½ï¼›
1. è¯»å†™ä»£ç 

```plain
//read.c
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <stdio.h>
#include <pthread.h>
int main()
{
    int i = 0;
    for(i = 0; ;i++)
    {
        char *filename = "test.log";
        int fd = open(filename, O_RDONLY);
        printf("fd=[%d]", fd);
        fflush(stdout);
        sleep(5);
    }
}

//write.c
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <stdio.h>
#include <pthread.h>
int main()
{
    int i = 0;
    for(i = 0; ;i++)
    {
        char *filename = "test.log";
        int fd = open(filename, O_CREAT | O_WRONLY | O_APPEND, S_IRUSR | S_IWUSR);
        write(fd, "aaaa\n", 6);
        printf("fd=[%d] buffer=[%s]", fd, "aaaa");
        close(fd);
        fflush(stdout);
        sleep(5);
    }
}
```

2. A ç”¨æˆ·æ‰§è¡Œ read, B ç”¨æˆ·æ‰§è¡Œ writeï¼›
 - a. A ç”¨æˆ·ï¼Œkill -9 ceph-fuse pid æ—¶é—´ç‚¹æ˜¯ 19:55:39ï¼›
 - b. è§‚å¯Ÿ A,B ç”¨æˆ·çš„æƒ…å†µå¦‚ä¸‹ï¼›
![image.png](https://upload-images.jianshu.io/upload_images/2099201-574b1c908e1f72b4.png)
 - c. è§‚å¯Ÿ mds çš„æ—¥å¿—ï¼›

```plain
2018-12-13 19:56:11.222816 7fffee6d0700  0 log_channel(cluster) log [WRN] : 1 slow requests, 1 included below; oldest blocked for > 30.670943 secs
2018-12-13 19:56:11.222826 7fffee6d0700  0 log_channel(cluster) log [WRN] : slow request 30.670943 seconds old, received at 2018-12-13 19:55:40.551820: client_request(client.22614489:538 lookup #0x1/test.log 2018-12-13 19:55:40.551681 caller_uid=0, caller_gid=0{0,}) currently failed to rdlock, waiting
2018-12-13 19:56:13.782378 7ffff0ed5700  1 mds.ceph-xxx-osd02.ys Updating MDS map to version 229049 from mon.0
2018-12-13 19:56:33.782572 7ffff0ed5700  1 mds.ceph-xxx-osd02.ys Updating MDS map to version 229050 from mon.0
2018-12-13 20:00:26.226405 7fffee6d0700  0 log_channel(cluster) log [WRN] : evicting unresponsive client ceph-xxx-osd01.ys (22532339), after 303.489228 seconds
```

**æ€»ç»“ï¼š**
 - å¯ä»¥å‘ç° kill ä¹‹å A ç”¨æˆ·æ˜¯ä¸å¯ç”¨çš„çŠ¶æ€ï¼›
 - ä¸æ­¤åŒæ—¶ B ç”¨æˆ·ä¹Ÿæ˜¯ä¸å¯ç”¨çš„çŠ¶æ€ï¼Œè¿‡äº† 300s æ‰æ¢å¤ï¼›
 - ä¸æ­¤åŒæ—¶ mds æ—¥å¿—æ˜¾ç¤ºï¼Œæœ‰æ…¢æŸ¥è¯¢ hang ä½çš„ client.22614489 æ­£å¥½æ˜¯ B ç”¨æˆ·ï¼›
 - mds æ—¥å¿—ä¸­å‘ç°ï¼Œhang ä½éƒ½æ˜¯åœ¨ç­‰å¾…è¯»é”(currently failed to rdlock, waitingï¼‰ï¼›
 - mds æ—¥å¿—ä¸­å‘ç°ï¼Œ hang ä½åè¿‡äº† 300s é©±é€å¼‚å¸¸å®¢æˆ·ç«¯ A ç”¨æˆ·ï¼›
 - æœ‰ä¸¤ç§æƒ…å†µå¯ä»¥è‡ªåŠ¨å‰”é™¤å®¢æˆ·ï¼š
    - åœ¨æ´»åŠ¨çš„ MDS å®ˆæŠ¤ç¨‹åºä¸Šï¼Œå¦‚æœå®¢æˆ·ç«¯å°šæœªé€šè¿‡ mds_session_autoclose ç§’ï¼ˆé»˜è®¤ä¸º 300 ç§’ï¼‰ä¸ MDS è¿›è¡Œé€šä¿¡(å®¢æˆ·ç«¯æ¯éš” 20s å‘ mds å‘é€å¿ƒè·³é“¾æ¥ handle_client_session)ï¼Œåˆ™ä¼šè‡ªåŠ¨å°†å…¶é€å‡ºï¼›
    - åœ¨ MDS å¯åŠ¨æœŸé—´ï¼ˆåŒ…æ‹¬æ•…éšœè½¬ç§»ï¼‰ï¼ŒMDS é€šè¿‡ç§°ä¸ºé‡æ–°è¿æ¥çš„çŠ¶æ€ï¼› åœ¨æ­¤çŠ¶æ€ä¸‹ï¼Œå®ƒç­‰å¾…æ‰€æœ‰å®¢æˆ·ç«¯è¿æ¥åˆ°æ–°çš„ MDS å®ˆæŠ¤ç¨‹åºã€‚ å¦‚æœä»»ä½•å®¢æˆ·ç«¯åœ¨æ—¶é—´çª—å£ï¼ˆmds_reconnect_timeoutï¼Œé»˜è®¤å€¼ä¸º 45 ç§’ï¼‰å†…æœªèƒ½è¿™æ ·åšï¼Œé‚£ä¹ˆå®ƒä»¬å°†è¢«é€å‡ºï¼›
 - è°ƒèŠ‚ mds session autoclose(é»˜è®¤ 300s)å¯ä»¥å°½å¿«é‡Šæ”¾å¼‚å¸¸ä¼šè¯ï¼Œè®©å…¶ä»–å®¢æˆ·ç«¯å°½å¿«å¯ç”¨ã€‚


## 7.3 MDS ä¸»ä»åˆ‡æ¢é—®é¢˜
### 7.3.1 ä¸ºä»€ä¹ˆ mds åˆ‡æ¢è€—æ—¶æ¯”è¾ƒé«˜
1. åˆ†ææ—¥å¿—(å‘ç°æ‰§è¡Œ rejoin_startï¼Œrejoin_joint_start åŠ¨ä½œè€—æ—¶æ¯”è¾ƒé«˜)ï¼›

```plain
2018-04-27 19:24:15.984156 7f53015d7700  1 mds.0.2738 rejoin_start
2018-04-27 19:25:15.987531 7f53015d7700  1 mds.0.2738 rejoin_joint_start
2018-04-27 19:27:40.105134 7f52fd4ce700  1 mds.0.2738 rejoin_done
2018-04-27 19:27:42.206654 7f53015d7700  1 mds.0.2738 handle_mds_map i am now mds.0.2738
2018-04-27 19:27:42.206658 7f53015d7700  1 mds.0.2738 handle_mds_map state change up:rejoin --> up:active
```

2. è·Ÿè¸ªä»£ç åˆ†æ(åœ¨æ‰§è¡Œ process_imported_caps è¶…æ—¶äº†ï¼Œ è¿™ä¸ªå‡½æ•°ä¸»è¦æ˜¯æ‰“å¼€ inodes åŠ è½½åˆ° cache ä¸­ï¼‰ï¼›
![image.png](https://upload-images.jianshu.io/upload_images/2099201-21dbf4e622b14877.png)

### 7.3.2 MDS åˆ‡æ¢å¾ªç¯
MDS å®ˆæŠ¤è¿›ç¨‹è‡³å°‘åœ¨ mds_beacon_grace ä¸­æœªèƒ½å‘ç›‘è§†å™¨å‘é€æ¶ˆæ¯ï¼Œè€Œå®ƒä»¬åº”è¯¥åœ¨æ¯ä¸ª mds_beacon_interval å‘é€æ¶ˆæ¯ï¼›æ­¤æ—¶ Ceph ç›‘è§†å™¨å°†è‡ªåŠ¨å°† MDS åˆ‡æ¢ä¸ºå¤‡ç”¨ MDSï¼›å¦‚æœ MDS çš„ Session Inode è¿‡å¤šå¯¼è‡´ MDS ç¹å¿™ï¼Œåªä»åˆ‡æ¢æœªèƒ½åŠæ—¶å‘é€æ¶ˆæ¯ï¼Œå°±å¯èƒ½ä¼šå‡ºç°å¾ªç¯åˆ‡æ¢çš„æ¦‚ç‡ï¼›ä¸€èˆ¬å»ºè®¾å¢å¤§ mds_beacon_graceï¼›

mds beacon grace
æè¿°:	å¤šä¹…æ²¡æ”¶åˆ°æ ‡è¯†æ¶ˆæ¯å°±è®¤ä¸º MDS è½åäº†ï¼ˆå¹¶å¯èƒ½æ›¿æ¢å®ƒï¼‰ï¼›
ç±»å‹:	Float
é»˜è®¤å€¼:	15



## 7.4 å®¢æˆ·ç«¯å¤±å»è¿æ¥
[client: fix fuse client hang because its pipe to mds is not ok](https://github.com/ceph/ceph/pull/24172)
There is a risk client will hang if fuse client session had been killed by mds and
the mds daemon restart or hot-standby switch happens right away but the client
did not receive any message from monitor due to network or other whatever reason
untill the mds become active again.Thus cause client didn't do closed_mds_session
lead the seession still is STATE_OPEN but client can't send any message to
mds because its pipe is not ok.

So we should create pipe to mds guarantee any meta request can be sent to
server.When mds recevie the message will send a CLOSE_SESSION to client
becasue its session for this client is STATE_CLOSED.After the previous
steps the old session of client can be closed and new session and pipe
can be established and the mountpoint will be ok.

# 8. æ€»ç»“åŠä¼˜åŒ–æ–¹æ¡ˆæ¨è

*   A ç”¨æˆ·è¯»æ•°æ®æ„å¤–æ‰çº¿ï¼ŒB ç”¨æˆ·çš„æ“ä½œéƒ½ä¼šæŠ—ä½ç­‰å¾… A ç”¨æˆ·æ¢å¤ï¼Œå¦‚æœæ¢å¤ä¸äº†ï¼Œç›´åˆ°ä¸€å®šæ—¶é—´ä¼šè‡ªåŠ¨å‰”é™¤ A ç”¨æˆ·(é”çš„ç²’åº¦å¾ˆå¤§ï¼Œå‘å¾ˆå¤§)ï¼›
*   è°ƒèŠ‚ mds session autoclose(é»˜è®¤ 300s)ï¼Œå°½å¿«å‰”é™¤æœ‰é—®é¢˜çš„å®¢æˆ·ç«¯ï¼›
    - On an active MDS daemon, if a client has not communicated with the MDS for over session_autoclose (a file system variable) seconds (300 seconds by default), then it will be evicted automatically
* æœ‰ä¸¤ç§æƒ…å†µå¯ä»¥è‡ªåŠ¨é©±é€å®¢æˆ·ï¼š
    - åœ¨æ´»åŠ¨çš„ MDS å®ˆæŠ¤ç¨‹åºä¸Šï¼Œå¦‚æœå®¢æˆ·ç«¯å°šæœªé€šè¿‡ mds_session_autoclose ç§’ï¼ˆé»˜è®¤ä¸º 300 ç§’ï¼‰ä¸ MDS è¿›è¡Œé€šä¿¡(å®¢æˆ·ç«¯æ¯éš” 20s å‘ mds å‘é€å¿ƒè·³é“¾æ¥ handle_client_session)ï¼Œåˆ™ä¼šè‡ªåŠ¨å°†å…¶é€å‡ºï¼›
    - åœ¨ MDS å¯åŠ¨æœŸé—´ï¼ˆåŒ…æ‹¬æ•…éšœè½¬ç§»ï¼‰ï¼ŒMDS é€šè¿‡ç§°ä¸ºé‡æ–°è¿æ¥çš„çŠ¶æ€ï¼›åœ¨æ­¤çŠ¶æ€ä¸‹ï¼Œå®ƒç­‰å¾…æ‰€æœ‰å®¢æˆ·ç«¯è¿æ¥åˆ°æ–°çš„ MDS å®ˆæŠ¤ç¨‹åºï¼› å¦‚æœä»»ä½•å®¢æˆ·ç«¯åœ¨æ—¶é—´çª—å£ï¼ˆmds_reconnect_timeoutï¼Œé»˜è®¤å€¼ä¸º 45 ç§’ï¼‰å†…æœªèƒ½è¿™æ ·åšï¼Œé‚£ä¹ˆå®ƒä»¬å°†è¢«é€å‡ºï¼›
*   å¦‚æœ mds è´Ÿè½½è¿‡é«˜æˆ–è€…å†…å­˜è¿‡å¤§ï¼Œé™åˆ¶ MDS å†…å­˜ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ï¼›mds limiting cache by memoryÂ [https://github.com/ceph/ceph/pull/17711](https://github.com/ceph/ceph/pull/17711)
*   å¦‚æœ mds è´Ÿè½½è¿‡é«˜æˆ–è€…å†…å­˜è¿‡å¤§ï¼Œå®˜æ–¹æä¾›çš„ mds ä¸»åŠ¨åˆ é™¤ cacheï¼Œè¡¥ä¸åœ¨ review è¿‡ç¨‹ä¸­ä¸ªï¼Œç›®æ ‡ç‰ˆæœ¬æ˜¯ ceph-14.0.0Â [https://github.com/ceph/ceph/pull/21566](https://github.com/ceph/ceph/pull/21566)
*   mds åœ¨ä¸»å¤„ç†æµç¨‹ä¸­ä½¿ç”¨äº†å•çº¿ç¨‹ï¼Œè¿™å¯¼è‡´äº†å…¶å•ä¸ª MDS çš„æ€§èƒ½å—åˆ°äº†é™åˆ¶ï¼Œæœ€å¤§å•ä¸ª MDS å¯è¾¾ 8k ops/sï¼ŒCPU åˆ©ç”¨ç‡è¾¾åˆ°çš„ 140%å·¦å³ï¼›
*   ceph-fuse å®¢æˆ·ç«¯ Qos é™é€Ÿï¼Œé¿å… IO ä¸€ç¬é—´æ¶Œè¿›æ¥å¯¼è‡´ mds æŠ–åŠ¨(ä»å®¢æˆ·ç«¯é™åˆ¶ IOPS,é¿å…èµ„æºäº‰æŠ¢ï¼Œå¯¹ç³»ç»Ÿèµ„æºå¸¦æ¥å†²å‡»)ï¼›
*   å‰”é™¤ç”¨æˆ·å¯ä»¥é‡Šæ”¾ inode æ•°é‡ï¼Œä½†æ˜¯ä¸èƒ½å‡å°‘å†…å­˜ï¼Œå¦‚æœæ­¤æ—¶åˆ‡æ¢ä¸»ä»å¯ä»¥åŠ å¿«åˆ‡æ¢é€Ÿåº¦ï¼›
*   å¤šæ´» MDS åœ¨ 12Â Luminous å®˜æ–¹å®£ç§°å¯ä»¥ä¸Šç”Ÿäº§ç¯å¢ƒï¼›
*   å½“æŸä¸ªæ–‡ä»¶ç³»ç»Ÿå®¢æˆ·ç«¯ä¸å“åº”æˆ–è€…æœ‰å…¶å®ƒå¼‚å¸¸è¡Œä¸ºæ—¶ï¼Œæ­¤æ—¶ä¼šå¯¹å®¢æˆ·ç«¯è¿›è¡Œé©±é€ï¼Œä¸ºäº†é˜²æ­¢å¼‚å¸¸å®¢æˆ·ç«¯å¯¼è‡´æ•°æ®ä¸ä¸€è‡´ï¼›

# 9. å¤šæ´» MDS
## 9.1 ç®€ä»‹
ä¹Ÿå«ï¼š multi-mds ã€ active-active MDS
æ¯ä¸ª CephFS æ–‡ä»¶ç³»ç»Ÿé»˜è®¤æƒ…å†µä¸‹éƒ½åªé…ç½®ä¸€ä¸ªæ´»è·ƒ MDS å®ˆæŠ¤è¿›ç¨‹ï¼›åœ¨å¤§å‹ç³»ç»Ÿä¸­ï¼Œä¸ºäº†æ‰©å±•å…ƒæ•°æ®æ€§èƒ½ä½ å¯ä»¥é…ç½®å¤šä¸ªæ´»è·ƒçš„ MDS å®ˆæŠ¤è¿›ç¨‹ï¼Œå®ƒä»¬ä¼šå…±åŒæ‰¿æ‹…å…ƒæ•°æ®è´Ÿè½½ï¼›

CephFS åœ¨ Luminous ç‰ˆæœ¬ä¸­å¤šå…ƒæ•°æ®æœåŠ¡å™¨ï¼ˆMulti-MDSï¼‰çš„åŠŸèƒ½å’Œç›®å½•åˆ†ç‰‡ï¼ˆdirfragmentï¼‰çš„åŠŸèƒ½å®£ç§°å·²ç»å¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ï¼›

![image.png](https://upload-images.jianshu.io/upload_images/2099201-a058e45972c30798.png)

## 9.2 å¤šæ´» MDS ä¼˜åŠ¿
 - å½“å…ƒæ•°æ®é»˜è®¤çš„å•ä¸ª MDS æˆä¸ºç“¶é¢ˆæ—¶ï¼Œé…ç½®å¤šä¸ªæ´»è·ƒçš„ MDS å®ˆæŠ¤è¿›ç¨‹ï¼Œæå‡é›†ç¾¤æ€§èƒ½ï¼›
 - å¤šä¸ªæ´»è·ƒçš„ MDS æœ‰åˆ©äºæ€§èƒ½æå‡ï¼›
 - å¤šä¸ªæ´»è·ƒçš„ MDS å¯ä»¥å®ç° MDS è´Ÿè½½å‡è¡¡ï¼›
 - å¤šä¸ªæ´»è·ƒçš„ MDS å¯ä»¥å®ç°å¤šç§Ÿæˆ·èµ„æºéš”ç¦»ï¼›

## 9.3 å¤šæ´» MDS ç‰¹ç‚¹
 - å®ƒèƒ½å¤Ÿå°†æ–‡ä»¶ç³»ç»Ÿæ ‘åˆ†å‰²æˆå­æ ‘ï¼›
 - æ¯ä¸ªå­æ ‘å¯ä»¥äº¤ç»™ç‰¹å®šçš„ MDS è¿›è¡Œæƒå¨ç®¡ç†ï¼›
 - ä»è€Œè¾¾åˆ°äº†éšç€å…ƒæ•°æ®æœåŠ¡å™¨æ•°é‡çš„å¢åŠ ï¼Œé›†ç¾¤æ€§èƒ½çº¿æ€§åœ°æ‰©å±•ï¼›
 - æ¯ä¸ªå­æ ‘éƒ½æ˜¯åŸºäºå…ƒæ•°æ®åœ¨ç»™å®šç›®å½•æ ‘ä¸­çš„çƒ­åŠ¨æ€åˆ›å»ºçš„ï¼›
 - ä¸€æ—¦åˆ›å»ºäº†å­æ ‘ï¼Œå®ƒçš„å…ƒæ•°æ®å°±è¢«è¿ç§»åˆ°ä¸€ä¸ªæœªåŠ è½½çš„ MDSï¼›
 - åç»­å®¢æˆ·ç«¯å¯¹å…ˆå‰æˆæƒçš„ MDS çš„è¯·æ±‚è¢«è½¬å‘ï¼›

![image.png](https://upload-images.jianshu.io/upload_images/2099201-9a39bbe653916339.png)

## 9.4 CephFS Subtree Partitioning
### 9.4.1 ä»‹ç»
![image.png](https://upload-images.jianshu.io/upload_images/2099201-249495dc7962a994.png)

**è¯´æ˜ï¼š**
ä¸ºäº†å®ç°æ–‡ä»¶ç³»ç»Ÿæ•°æ®å’Œå…ƒæ•°æ®çš„è´Ÿè½½å‡è¡¡ï¼Œä¸šç•Œä¸€èˆ¬æœ‰å‡ ç§åˆ†åŒºæ–¹æ³•ï¼š
 - é™æ€å­æ ‘åˆ†åŒº
   - å³é€šè¿‡æ‰‹å·¥åˆ†åŒºæ–¹å¼ï¼Œå°†æ•°æ®ç›´æ¥åˆ†é…åˆ°æŸä¸ªæœåŠ¡èŠ‚ç‚¹ä¸Šï¼Œå‡ºç°è´Ÿè½½
   ä¸å‡è¡¡æ—¶ï¼Œå†ç”±ç®¡ç†å‘˜æ‰‹åŠ¨é‡æ–°è¿›è¡Œåˆ†é…ï¼›
   - è¿™ç§æ–¹å¼é€‚åº”äºæ•°æ®ä½ç½®å›ºå®šçš„åœºæ™¯ï¼Œä¸é€‚åˆåŠ¨æ€æ‰©å±•ã€æˆ–è€…æœ‰å¯èƒ½å‡ºç°å¼‚å¸¸çš„åœºæ™¯ï¼›
 - Hash è®¡ç®—åˆ†åŒº
   - å³é€šè¿‡ Hash è®¡ç®—æ¥åˆ†é…æ•°æ®å­˜å‚¨çš„ä½ç½®ï¼›
   - è¿™ç§æ–¹å¼é€‚åˆæ•°æ®åˆ†å¸ƒå‡è¡¡ã€ä¸”éœ€è¦åº”ç”¨å„ç§å¼‚å¸¸çš„æƒ…å†µï¼Œä½†ä¸å¤ªé€‚åˆéœ€è¦æ•°æ®åˆ†å¸ƒå›ºå®šã€ç¯å¢ƒå˜åŒ–é¢‘ç‡å¾ˆé«˜çš„åœºæ™¯ï¼›
 - åŠ¨æ€å­æ ‘åˆ†åŒº
   - é€šè¿‡å®æ—¶ç›‘æ§é›†ç¾¤èŠ‚ç‚¹çš„è´Ÿè½½ï¼ŒåŠ¨æ€è°ƒæ•´å­æ ‘åˆ†å¸ƒäºä¸åŒçš„èŠ‚ç‚¹ï¼›
   - è¿™ç§æ–¹å¼é€‚åˆå„ç§å¼‚å¸¸åœºæ™¯ï¼Œèƒ½æ ¹æ®è´Ÿè½½çš„æƒ…å†µï¼ŒåŠ¨æ€çš„è°ƒæ•´æ•°æ®åˆ†å¸ƒï¼Œä¸è¿‡å¦‚æœå¤§é‡æ•°æ®çš„è¿ç§»è‚¯å®šä¼šå¯¼è‡´ä¸šåŠ¡æŠ–åŠ¨ï¼Œå½±å“æ€§èƒ½ï¼›

## 9.5 Subtree Pinning(static subtree partitioning)
![image.png](https://upload-images.jianshu.io/upload_images/2099201-3c36dd0e05e73e85.png)

**è¯´æ˜ï¼š**

 - é€šè¿‡ pin å¯ä»¥æŠŠ mds å’Œç›®å½•è¿›è¡Œç»‘å®š ï¼›
 - é€šè¿‡ pin å¯ä»¥åšåˆ°ä¸åŒç”¨æˆ·çš„ç›®å½•è®¿é—®ä¸åŒçš„ mdsï¼›
 - å¯ä»¥å®ç°å¤šç§Ÿæˆ· MDS è´Ÿè½½å‡è¡¡ï¼›
 - å¯ä»¥å®ç°å¤šç§Ÿæˆ· MDS è´Ÿè½½èµ„æºéš”ç¦»ï¼›

## 9.6 åŠ¨æ€è´Ÿè½½å‡è¡¡
### 9.6.1 ä»‹ç»
å¤šä¸ªæ´»åŠ¨çš„ MDSs å¯ä»¥è¿ç§»ç›®å½•ä»¥å¹³è¡¡å…ƒæ•°æ®è´Ÿè½½ï¼›ä½•æ—¶ã€ä½•åœ°ä»¥åŠè¿ç§»å¤šå°‘çš„ç­–ç•¥éƒ½è¢«ç¡¬ç¼–ç åˆ°å…ƒæ•°æ®å¹³è¡¡æ¨¡å—ä¸­ï¼›

Mantle æ˜¯ä¸€ä¸ªå†…ç½®åœ¨ MDS ä¸­çš„å¯ç¼–ç¨‹å…ƒæ•°æ®å‡è¡¡å™¨ï¼›å…¶æ€æƒ³æ˜¯ä¿æŠ¤å¹³è¡¡è´Ÿè½½(è¿ç§»ã€å¤åˆ¶ã€ç¢ç‰‡åŒ–)çš„æœºåˆ¶ï¼Œä½†ä½¿ç”¨ Lua å®šåˆ¶åŒ–å¹³è¡¡ç­–ç•¥ï¼›

å¤§å¤šæ•°å®ç°éƒ½åœ¨ MDBalancer ä¸­ï¼›åº¦é‡é€šè¿‡ Lua æ ˆä¼ é€’ç»™å‡è¡¡å™¨ç­–ç•¥ï¼Œè´Ÿè½½åˆ—è¡¨è¿”å›ç»™ MDBalancerï¼›è¿™äº›è´Ÿè½½æ˜¯â€œå‘é€åˆ°æ¯ä¸ª MDS çš„æ•°é‡â€ï¼Œå¹¶ç›´æ¥æ’å…¥ MDBalancerâ€œmy_targetsâ€å‘é‡ï¼›

æš´éœ²ç»™ Lua ç­–ç•¥çš„æŒ‡æ ‡ä¸å·²ç»å­˜å‚¨åœ¨ mds_load_t ä¸­çš„æŒ‡æ ‡ç›¸åŒ:auth.meta_load()ã€all.meta_load()ã€req_rateã€queue_lengthã€cpu_load_avgï¼›

å®ƒä½äºå½“å‰çš„å‡è¡¡å™¨å®ç°æ—è¾¹ï¼Œå¹¶ä¸”å®ƒæ˜¯é€šè¿‡â€œceph.confâ€ä¸­çš„å­—ç¬¦ä¸²å¯ç”¨çš„ï¼›å¦‚æœ Lua ç­–ç•¥å¤±è´¥(æ— è®ºå‡ºäºä½•ç§åŸå› )ï¼Œæˆ‘ä»¬å°†å›åˆ°åŸæ¥çš„å…ƒæ•°æ®è´Ÿè½½å‡è¡¡å™¨ï¼›
å‡è¡¡å™¨å­˜å‚¨åœ¨ RADOS å…ƒæ•°æ®æ± ä¸­ï¼ŒMDSMap ä¸­çš„å­—ç¬¦ä¸²å‘Šè¯‰ MDSs ä½¿ç”¨å“ªä¸ªå‡è¡¡å™¨ï¼›

This PR does notÂ notÂ have the following features from the Supercomputing paper:
1.  Balancing API: all we require is that balancer written in Lua returns aÂ `targets`Â table, where each index is the amount of load to send to each MDS
2.  "How much" hook: this let's the user defineÂ `meta_load()`
3.  Instantaneous CPU utilization as metric
Supercomputing '15 Paper:Â [http://sc15.supercomputing.org/schedule/event_detail-evid=pap168.html](http://sc15.supercomputing.org/schedule/event_detail-evid=pap168.html)

### 9.6.2 å¯é…ç½®çš„è´Ÿè½½å‡è¡¡
![image.png](https://upload-images.jianshu.io/upload_images/2099201-e8eb98f1cec30ec8.png)

**å‚è€ƒï¼š**
*   [http://docs.ceph.com/docs/mimic/cephfs/mds-config-ref/](http://docs.ceph.com/docs/mimic/cephfs/mds-config-ref/)
* [https://github.com/ceph/ceph/blob/master/src/mds/MDBalancer.cc#L207](https://github.com/ceph/ceph/blob/master/src/mds/MDBalancer.cc)

### 9.6.3 è´Ÿè½½å‡è¡¡ç­–ç•¥
![image.png](https://upload-images.jianshu.io/upload_images/2099201-795715bf3c6c97e2.png)

### 9.6.4 é€šè¿‡ lua çµæ´»æ§åˆ¶è´Ÿè½½å‡è¡¡
![image.png](https://upload-images.jianshu.io/upload_images/2099201-d77bd8b5e59a783a.png)
**å‚è€ƒï¼š**
*   [https://www.soe.ucsc.edu/sites/default/files/technical-reports/UCSC-SOE-15-10.pdf](https://www.soe.ucsc.edu/sites/default/files/technical-reports/UCSC-SOE-15-10.pdf)
*   [https://github.com/ceph/ceph/blob/master/src/mds/balancers/greedyspill.lua#L16](https://github.com/ceph/ceph/blob/master/src/mds/balancers/greedyspill.lua#L16)

### 9.6.5 å†…éƒ¨ç»“æ„å›¾
![image.png](https://upload-images.jianshu.io/upload_images/2099201-0a21cf6d0061cd72.png)
**å‚è€ƒï¼š**
*   [https://www.soe.ucsc.edu/sites/default/files/technical-reports/UCSC-SOE-15-10.pdf](https://www.soe.ucsc.edu/sites/default/files/technical-reports/UCSC-SOE-15-10.pdf)

# 10. å¤šæ´»è´Ÿè½½å‡è¡¡-å®æˆ˜æ¼”ç»ƒ
## 10.1 é›†ç¾¤æ¶æ„
 - mon: ceph-xxx-osd02.ys,ceph-xxx-osd03.ys,ceph-xxx-osd01.ys
 - mgr: ceph-xxx-osd03.ys(active), standbys: ceph-xxx-osd02.ys
 - mds: test1_fs-1/1/1 up  {0=ceph-xxx-osd02.ys=up:active}, 2 up:standby
 - osd: 36 osds: 36 up, 36 in
 - rgw: 1 daemon active

## 10.2 æ‰©å®¹æ´»è·ƒ MDS
### 10.2.1 è®¾ç½® max_mds ä¸º 2

```plain
$ ceph fs set test1_fs max_mds 2
```

### 10.2.2 æŸ¥çœ‹ fs çŠ¶æ€ä¿¡æ¯

```plain

$ ceph fs status
test1_fs - 3 clients
========
+------+--------+------------------------+---------------+-------+-------+
| Rank | State  |          MDS           |    Activity   |  dns  |  inos |
+------+--------+------------------------+---------------+-------+-------+
|  0   | active | ceph-xxx-osd02.ys | Reqs:    0 /s | 3760  |   14  |
|  1   | active | ceph-xxx-osd01.ys | Reqs:    0 /s |   11  |   13  |
+------+--------+------------------------+---------------+-------+-------+
+-----------------+----------+-------+-------+
|       Pool      |   type   |  used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata |  194M | 88.7T |
|   cephfs_data   |   data   |    0  | 88.7T |
+-----------------+----------+-------+-------+
+------------------------+
|      Standby MDS       |
+------------------------+
| ceph-xxx-osd03.ys |
+------------------------+
MDS version: didi_dss version 12.2.8 (ae699615bac534ea496ee965ac6192cb7e0e07c0) luminous (stable)
```

### 10.2.3 æ€»ç»“
 - æ¯ä¸€ä¸ª CephFS æ–‡ä»¶ç³»ç»Ÿéƒ½æœ‰è‡ªå·±çš„ max_mds é…ç½®ï¼Œå®ƒæ§åˆ¶ç€ä¼šåˆ›å»ºå¤šå°‘ rank ï¼›
 - æœ‰ç©ºé—²å®ˆæŠ¤è¿›ç¨‹å¯æ¥ç®¡æ–° rank æ—¶ï¼Œæ–‡ä»¶ç³»ç»Ÿ rank çš„å®é™…æ•°é‡æ‰ä¼šå¢åŠ  ï¼›
 - é€šè¿‡è®¾ç½® max_mds å¢åŠ  active mdsï¼›
    - æ–°åˆ›å»ºçš„ rank (1) ä¼šä» creating çŠ¶æ€è¿‡æ¸¡åˆ° active çŠ¶æ€ï¼›
    - åˆ›å»ºåæœ‰ä¸¤ä¸ª active mdsï¼Œ ä¸€ä¸ª standby mdsï¼›

## 10.3 å¤šæ´» MDS å‹æµ‹
### 10.3.1 ç”¨æˆ·æŒ‚è½½ç›®å½•

```plain
$ ceph-fuse /mnt/
$ df
ceph-fuse      95330861056     40960 95330820096   1% /mnt
```

### 10.3.2 filebench å‹æµ‹
![image.png](https://upload-images.jianshu.io/upload_images/2099201-eccdc1a24b87b716.png)

### 10.3.3 æŸ¥çœ‹ fs mds è´Ÿè½½

```plain

$ ceph fs status
test1_fs - 3 clients
========
+------+--------+------------------------+---------------+-------+-------+
| Rank | State  |          MDS           |    Activity   |  dns  |  inos |
+------+--------+------------------------+---------------+-------+-------+
|  0   | active | ceph-xxx-osd03.ys | Reqs: 5624 /s |  139k |  133k |
+------+--------+------------------------+---------------+-------+-------+
+-----------------+----------+-------+-------+
|       Pool      |   type   |  used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata |  238M | 88.7T |
|   cephfs_data   |   data   | 2240M | 88.7T |
+-----------------+----------+-------+-------+
+------------------------+
|      Standby MDS       |
+------------------------+
| ceph-xxx-osd01.ys |
| ceph-xxx-osd02.ys |
+------------------------+
MDS version: didi_dss version 12.2.8 (ae699615bac534ea496ee965ac6192cb7e0e07c0) luminous (stable)
```

### 10.3.4 æ€»ç»“
 - fuse æ¨¡å¼ mds æ€§èƒ½ 5624 ops/sï¼›
 - è™½ç„¶æœ‰ä¸¤ä¸ª active mds, ä½†æ˜¯ç›®å‰è¯·æ±‚éƒ½ä¼šè½åœ¨ rank0 ä¸Šé¢ï¼›
 - é»˜è®¤å¤šä¸ª active mds è´Ÿè½½å¹¶æ²¡æœ‰å‡è¡¡ï¼›

## 10.4 å¤šæ´» MDS-åŠ¨æ€è´Ÿè½½å‡è¡¡
### 10.4.1 Put the balancer into RADOS

```plain
rados put --pool=cephfs_metadata_a greedyspill.lua ../src/mds/balancers/greedyspill.lua
```

### 10.4.2 Activate Mantle

```plain
ceph fs set test1_fs max_mds 2
ceph fs set test1_fs balancer greedyspill.lua
```

### 10.4.3 æŒ‚è½½å‹æµ‹

```plain
$ ceph fs status
test1_fs - 3 clients
========
+------+--------+------------------------+---------------+-------+-------+
| Rank | State | MDS | Activity | dns | inos |
+------+--------+------------------------+---------------+-------+-------+
| 0 | active | ceph-xxx-osd03.ys | Reqs: 2132 /s | 4522 | 1783 |
| 1 | active | ceph-xxx-osd02.ys | Reqs: 173 /s | 306 | 251 |
+------+--------+------------------------+---------------+-------+-------+
+-----------------+----------+-------+-------+
| Pool | type | used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata | 223M | 88.7T |
| cephfs_data | data | 27.1M | 88.7T |
+-----------------+----------+-------+-------+
+------------------------+
| Standby MDS |
+------------------------+
| ceph-xxx-osd01.ys |
+------------------------+
MDS version: didi_dss version 12.2.8 (ae699615bac534ea496ee965ac6192cb7e0e07c0) luminous (stable)
```

### 10.4.4 æ€»ç»“
 - é€šè¿‡ lua å¯ä»¥çµæ´»æ§åˆ¶è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼›
 - æµ‹è¯•ç»“æœå‘ç°ï¼Œè´Ÿè½½å‡è¡¡æ•ˆæœå¹¶ä¸å¥½ï¼›
 - **è´Ÿè½½å‡è¡¡ç›®å‰æ¥çœ‹å‘æ¯”è¾ƒæ·±ï¼Œç›®å‰ä¸æ¨èä½¿ç”¨**ï¼›

## 10.5 å¤šæ´» MDS-é™æ€åˆ†åŒº(å¤šç§Ÿæˆ·éš”ç¦»)
### 10.5.1 æ ¹æ®ç›®å½•ç»‘å®šä¸åŒçš„ mds

```plain
#mds00ç»‘å®šåˆ°/mnt/test0
#mds01ç»‘å®šåˆ°/mnt/test1
#setfattr -n ceph.dir.pin -v <rank> <path>

setfattr -n ceph.dir.pin -v 0 /mnt/test0
setfattr -n ceph.dir.pin -v 1 /mnt/test1
```

### 10.5.2 ä¸¤ä¸ªå®¢æˆ·ç«¯å‹æµ‹
![image.png](https://upload-images.jianshu.io/upload_images/2099201-825def88159304cc.png)

### 10.5.3 è§‚å¯Ÿ fs çŠ¶æ€ä¿¡æ¯(2 ä¸ªå‹æµ‹ç«¯)

```plain
#æ£€æŸ¥mdsè¯·æ±‚è´Ÿè´£æƒ…å†µ
$ ceph fs status
test1_fs - 3 clients
========
+------+--------+------------------------+---------------+-------+-------+
| Rank | State  |          MDS           |    Activity   |  dns  |  inos |
+------+--------+------------------------+---------------+-------+-------+
|  0   | active | ceph-xxx-osd03.ys | Reqs: 3035 /s |  202k |  196k |
|  1   | active | ceph-xxx-osd02.ys | Reqs: 3039 /s | 70.8k | 66.0k |
+------+--------+------------------------+---------------+-------+-------+
+-----------------+----------+-------+-------+
|       Pool      |   type   |  used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata |  374M | 88.7T |
|   cephfs_data   |   data   | 4401M | 88.7T |
+-----------------+----------+-------+-------+
+------------------------+
|      Standby MDS       |
+------------------------+
| ceph-xxx-osd01.ys |
+------------------------+
MDS version: didi_dss version 12.2.8 (ae699615bac534ea496ee965ac6192cb7e0e07c0) luminous (stable)
```

### 10.5.4 ç»“è®º
 - é€šè¿‡ ceph.dir.pin æŠŠç›®å½•ç»‘å®šåˆ°ä¸åŒçš„ mds ä¸Šï¼Œä»è€Œå®ç°å¤šç§Ÿæˆ·éš”ç¦»ï¼›
 - ä¸¤ä¸ªå®¢æˆ·ç«¯å„è‡ªå†™å…¥è‡ªå·±æ‰€åœ¨ç›®å½•æŒç»­å‹æµ‹ 20 åˆ†é’Ÿï¼›
 - ä¸¤ä¸ªå®¢æˆ·ç«¯å‹æµ‹ç»“æœåˆ†åˆ«æ˜¯ï¼š3035 ops/sï¼Œ3039 ops/sï¼›
 - ä¸¤ä¸ªå®¢æˆ·ç«¯ cpu æ¶ˆè€—éå¸¸æ¥è¿‘ï¼›
 - ä¸¤ä¸ª active mds ç›®å‰éƒ½æœ‰è¯·æ±‚è´Ÿè½½ï¼Œå®ç°äº†å¤šä¸ªå®¢æˆ·ç«¯çš„è´Ÿè½½å‡è¡¡ï¼›

## 10.6 å¤šæ´» MDS-ä¸»å¤‡æ¨¡å¼
### 10.6.1 æŸ¥çœ‹ mds çŠ¶æ€

```plain
$ ceph fs status
test1_fs - 4 clients
========
+------+--------+------------------------+---------------+-------+-------+
| Rank | State  |          MDS           |    Activity   |  dns  |  inos |
+------+--------+------------------------+---------------+-------+-------+
|  0   | active | ceph-xxx-osd02.ys | Reqs:    0 /s | 75.7k | 72.6k |
|  1   | active | ceph-xxx-osd01.ys | Reqs:    0 /s | 67.8k | 64.0k |
+------+--------+------------------------+---------------+-------+-------+
+-----------------+----------+-------+-------+
|       Pool      |   type   |  used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata |  311M | 88.7T |
|   cephfs_data   |   data   | 3322M | 88.7T |
+-----------------+----------+-------+-------+
+------------------------+
|      Standby MDS       |
+------------------------+
| ceph-xxx-osd03.ys |
+------------------------+
MDS version: didi_dss version 12.2.8 (ae699615bac534ea496ee965ac6192cb7e0e07c0) luminous (stable)
```

### 10.6.2 åœæ‰ mds2

```plain
$ systemctl stop ceph-mds.target
```

### 10.6.3 æŸ¥çœ‹ mds çŠ¶æ€ä¿¡æ¯

```plain
$ ceph fs status
test1_fs - 2 clients
========
+------+--------+------------------------+---------------+-------+-------+
| Rank | State  |          MDS           |    Activity   |  dns  |  inos |
+------+--------+------------------------+---------------+-------+-------+
|  0   | replay | ceph-xxx-osd03.ys |               |    0  |    0  |
|  1   | active | ceph-xxx-osd01.ys | Reqs:    0 /s | 67.8k | 64.0k |
+------+--------+------------------------+---------------+-------+-------+
+-----------------+----------+-------+-------+
|       Pool      |   type   |  used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata |  311M | 88.7T |
|   cephfs_data   |   data   | 3322M | 88.7T |
+-----------------+----------+-------+-------+
+-------------+
| Standby MDS |
+-------------+
+-------------+
MDS version: didi_dss version 12.2.8 (ae699615bac534ea496ee965ac6192cb7e0e07c0) luminous (stable)
```

### 10.6.4 å‹æµ‹è§‚å¯Ÿ

```plain
#è¿›è¡Œå‹æµ‹rank0, å‘ç°è¯·æ±‚èƒ½æ­£å¸¸è½åœ¨mds3ä¸Š
$ ceph fs status
test1_fs - 4 clients
========
+------+--------+------------------------+---------------+-------+-------+
| Rank | State  |          MDS           |    Activity   |  dns  |  inos |
+------+--------+------------------------+---------------+-------+-------+
|  0   | active | ceph-xxx-osd03.ys | Reqs: 2372 /s | 72.7k | 15.0k |
|  1   | active | ceph-xxx-osd01.ys | Reqs:    0 /s | 67.8k | 64.0k |
+------+--------+------------------------+---------------+-------+-------+
+-----------------+----------+-------+-------+
|       Pool      |   type   |  used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata |  367M | 88.7T |
|   cephfs_data   |   data   | 2364M | 88.7T |
+-----------------+----------+-------+-------+
+------------------------+
|      Standby MDS       |
+------------------------+
| ceph-xxx-osd02.ys |
+------------------------+
MDS version: didi_dss version 12.2.8 (ae699615bac534ea496ee965ac6192cb7e0e07c0) luminous (stable)
```

### 10.6.5 æ€»ç»“
 - å¤š active mdsï¼Œå¦‚æœä¸» mds æŒ‚æ‰ï¼Œ å¤‡ mds ä¼šæ¥æ›¿ä¸»çš„ä½ç½®ï¼›
 - æ–°çš„ä¸»ä¼šç»§æ‰¿é™æ€åˆ†åŒºå…³ç³»ï¼›

# 11. å¤šæ´»è´Ÿè½½å‡è¡¡-æ€»ç»“
## 11.1 æµ‹è¯•æŠ¥å‘Š
|  å·¥å…· | é›†ç¾¤æ¨¡å¼ | å®¢æˆ·ç«¯æ•°é‡(å‹æµ‹ç«¯) |  æ€§èƒ½ |
|:---:|:---:|:---:|:---:|
| filebench |  1MDS |  2 ä¸ªå®¢æˆ·ç«¯ | 5624 ops/s |
| filebench | 2MDS | 2 ä¸ªå®¢æˆ·ç«¯ | å®¢æˆ·ç«¯ 1ï¼š3035 ops/s <br>å®¢æˆ·ç«¯ 2ï¼š3039 ops/s |
## 11.2 ç»“è®º
 - å•æ´» mds
      - æ€§èƒ½æ˜¯ 5624 ops/s å·¦å³ï¼›
      - é€šè¿‡ä¸»å¤‡æ¨¡å¼å¯ä»¥å®ç°é«˜å¯ç”¨ï¼›
 - å¤šæ´» mds é»˜è®¤
      - ç”¨æˆ·çš„è¯·æ±‚éƒ½åªä¼šåœ¨ rank 0 ä¸Šçš„ mdsï¼›
 - å¤šæ´» mds åŠ¨æ€è´Ÿè½½å‡è¡¡   (ç›®å‰ 12.2 ç‰ˆæœ¬ä¸æ¨èä½¿ç”¨)
      - æµ‹è¯•æ•ˆæœå¤šä¸ª mds è´Ÿè½½ä¸å‡è¡¡ï¼›
      - å¯ä»¥é€šè¿‡ lua çµæ´»è°ƒèŠ‚è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼›
      - èµ„æºæ¥å›è¿ç§»ç­‰å„ç§é—®é¢˜ï¼Œç›®å‰æ„Ÿè§‰å‘è¿˜æ˜¯å¾ˆå¤§ï¼›
  - å¤šæ´» mds é™æ€åˆ†åŒºï¼ˆæ¨èä½¿ç”¨ï¼Œå¤–ç•Œç¤¾åŒºä¹Ÿæœ‰ç”¨åˆ°ç”Ÿäº§ç¯å¢ƒ)
      - å¯ä»¥å®ç°ä¸åŒç›®å½•ç»‘å®šåˆ°ä¸åŒçš„ mds ä¸Šï¼›
      - ä»è€Œå®ç°å¤šç§Ÿæˆ· mds èµ„æºéš”ç¦»ï¼›
      - éšç€ mds å¢åŠ å¯ä»¥çº¿æ€§å¢åŠ é›†ç¾¤æ€§èƒ½ï¼›
      - ä¸¤ä¸ªå®¢æˆ·ç«¯å‹æµ‹ç»“æœåˆ†åˆ«æ˜¯ï¼š3035 ops/sï¼Œ3039 ops/sï¼›
 - å¤šæ´» mds ä¸»å¤‡æ¨¡å¼
      - å…¶ä¸­ä¸€ä¸ª active mds æŒ‚æ‰ stanbdy ä¼šç«‹é©¬æ¥æ›¿ï¼›
      - æ¥æ›¿è¿‡æ¥çš„æ–°ä¸» active mds ä¹Ÿä¼šç»§æ‰¿é™æ€åˆ†åŒºçš„å…³ç³»ï¼›

# 12. MDS çŠ¶æ€è¯´æ˜
## 12.1 MDS ä¸»ä»åˆ‡æ¢æµç¨‹å›¾
![image.png](https://upload-images.jianshu.io/upload_images/2099201-fd69f342b19fcdf4.png)

**è¯´æ˜ï¼š**
 1. ç”¨æˆ·æ‰‹åŠ¨å‘èµ·ä¸»ä»åˆ‡æ¢ failï¼›
 2. active mds æ‰‹åŠ¨ä¿¡å·ï¼Œå‘èµ· respawn é‡å¯ï¼›
 3. standby mds æ”¶åˆ°ä¿¡å·ï¼Œç»è¿‡åˆ†å¸ƒå¼ç®—æ³•æ¨é€‰ä¸ºæ–°ä¸» active mdsï¼›
 4. æ–°ä¸» active mds ä» up:boot çŠ¶æ€ï¼Œå˜æˆ up:replay çŠ¶æ€ï¼›æ—¥å¿—æ¢å¤é˜¶æ®µï¼Œä»–å°†æ—¥å¿—å†…å®¹è¯»å…¥å†…å­˜åï¼Œåœ¨å†…å­˜ä¸­è¿›è¡Œå›æ”¾æ“ä½œï¼›
 5. æ–°ä¸» active mds ä» up:replay çŠ¶æ€ï¼Œå˜æˆ up:reconnect çŠ¶æ€ï¼›æ¢å¤çš„ mds éœ€è¦ä¸ä¹‹å‰çš„å®¢æˆ·ç«¯é‡æ–°å»ºç«‹è¿æ¥ï¼Œå¹¶ä¸”éœ€è¦æŸ¥è¯¢ä¹‹å‰å®¢æˆ·ç«¯å‘å¸ƒçš„æ–‡ä»¶å¥æŸ„ï¼Œé‡æ–°åœ¨ mds çš„ç¼“å­˜ä¸­åˆ›å»ºä¸€è‡´æ€§åŠŸèƒ½å’Œé”çš„çŠ¶æ€ï¼›
 6. æ–°ä¸» active mds ä» up:reconnect çŠ¶æ€ï¼Œå˜æˆ up:rejoin çŠ¶æ€ï¼›æŠŠå®¢æˆ·ç«¯çš„ inode åŠ è½½åˆ° mds cacheï¼›(è€—æ—¶æœ€å¤šçš„åœ°æ–¹)
 7. æ–°ä¸» active mds ä» up:rejoin çŠ¶æ€ï¼Œå˜æˆ up:active çŠ¶æ€ï¼›mds çŠ¶æ€å˜æˆæ­£å¸¸å¯ç”¨çš„çŠ¶æ€ï¼›
 8. recovery_done è¿ç§»å®Œæ¯•ï¼›
 9. active_start æ­£å¸¸å¯ç”¨çŠ¶æ€å¯åŠ¨ï¼Œmdcache åŠ è½½ç›¸åº”çš„ä¿¡æ¯ï¼›

## 12.2 MDS çŠ¶æ€
| çŠ¶æ€ | è¯´æ˜ |
|----|----|
|up:active | This is the normal operating state of the MDS. It indicates that the MDS and its rank in the file system is available.<br><br>è¿™ä¸ªçŠ¶æ€æ˜¯æ­£å¸¸è¿è¡Œçš„çŠ¶æ€ã€‚ è¿™ä¸ªè¡¨æ˜è¯¥ mds åœ¨ rank ä¸­æ˜¯å¯ç”¨çš„çŠ¶æ€ã€‚|
|up:standby | The MDS is available to takeover for a failed rank (see alsoÂ [:ref:`mds-standby`](https://github.com/ceph/ceph/blob/master/doc/cephfs/mds-states.rst#id1)). The monitor will automatically assign an MDS in this state to a failed rank once available.<br><br>è¿™ä¸ªçŠ¶æ€æ˜¯ç¾å¤‡çŠ¶æ€ï¼Œç”¨æ¥æ¥æ›¿ä¸»æŒ‚æ‰çš„æƒ…å†µã€‚|
|up:standby_replay | The MDS is following the journal of another up:active MDS. Should the active MDS fail, having a standby MDS in replay mode is desirable as the MDS is replaying the live journal and will more quickly takeover. A downside to having standby replay MDSs is that they are not available to takeover for any other MDS that fails, only the MDS they follow.<br><br>ç¾å¤‡å®ˆæŠ¤è¿›ç¨‹å°±ä¼šæŒç»­è¯»å–æŸä¸ªå¤„äº up çŠ¶æ€çš„ rank çš„å…ƒæ•°æ®æ—¥å¿—ã€‚è¿™æ ·å®ƒå°±æœ‰å…ƒæ•°æ®çš„çƒ­ç¼“å­˜ï¼Œåœ¨è´Ÿè´£è¿™ä¸ª rank çš„å®ˆæŠ¤è¿›ç¨‹å¤±æ•ˆæ—¶ï¼Œå¯åŠ é€Ÿæ•…éšœåˆ‡æ¢ã€‚<br><br> ä¸€ä¸ªæ­£å¸¸è¿è¡Œçš„ rank åªèƒ½æœ‰ä¸€ä¸ªç¾å¤‡é‡æ”¾å®ˆæŠ¤è¿›ç¨‹ï¼ˆ standby replay daemon ï¼‰ï¼Œå¦‚æœä¸¤ä¸ªå®ˆæŠ¤è¿›ç¨‹éƒ½è®¾ç½®æˆäº†ç¾å¤‡é‡æ”¾çŠ¶æ€ï¼Œé‚£ä¹ˆå…¶ä¸­ä»»æ„ä¸€ä¸ªä¼šå–èƒœï¼Œå¦ä¸€ä¸ªä¼šå˜ä¸ºæ™®é€šçš„ã€éé‡æ”¾ç¾å¤‡çŠ¶æ€ã€‚<br><br>ä¸€æ—¦æŸä¸ªå®ˆæŠ¤è¿›ç¨‹è¿›å…¥ç¾å¤‡é‡æ”¾çŠ¶æ€ï¼Œå®ƒå°±åªèƒ½ä¸ºå®ƒé‚£ä¸ª rank æä¾›ç¾å¤‡ã€‚å¦‚æœæœ‰å¦å¤–ä¸€ä¸ª rank å¤±æ•ˆäº†ï¼Œå³ä½¿æ²¡æœ‰ç¾å¤‡å¯ç”¨ï¼Œè¿™ä¸ªç¾å¤‡é‡æ”¾å®ˆæŠ¤è¿›ç¨‹ä¹Ÿä¸ä¼šå»é¡¶æ›¿é‚£ä¸ªå¤±æ•ˆçš„ã€‚|
|up:boot | This state is broadcast to the Ceph monitors during startup. This state is never visible as the Monitor immediately assign the MDS to an available rank or commands the MDS to operate as a standby. The state is documented here for completeness. <br><br> æ­¤çŠ¶æ€åœ¨å¯åŠ¨æœŸé—´è¢«å¹¿æ’­åˆ° CEPH ç›‘è§†å™¨ã€‚è¿™ç§çŠ¶æ€æ˜¯ä¸å¯è§çš„ï¼Œå› ä¸ºç›‘è§†å™¨ç«‹å³å°† MDS åˆ†é…ç»™å¯ç”¨çš„ç§©æˆ–å‘½ä»¤ MDS ä½œä¸ºå¤‡ç”¨æ“ä½œã€‚è¿™é‡Œè®°å½•äº†å®Œæ•´æ€§çš„çŠ¶æ€ã€‚|
|up:creating | The MDS is creating a new rank (perhaps rank 0) by constructing some per-rank metadata (like the journal) and entering the MDS cluster. |
|up:starting | The MDS is restarting a stopped rank. It opens associated per-rank metadata and enters the MDS cluster. |
|up:stopping | When a rank is stopped, the monitors command an active MDS to enter theÂ `up:stopping`Â state. In this state, the MDS accepts no new client connections, migrates all subtrees to other ranks in the file system, flush its metadata journal, and, if the last rank (0), evict all clients and shutdown (see alsoÂ [:ref:`cephfs-administration`](https://github.com/ceph/ceph/blob/master/doc/cephfs/mds-states.rst#id3)). |
|up:replay | The MDS taking over a failed rank. This state represents that the MDS is recovering its journal and other metadata.<br><br>æ—¥å¿—æ¢å¤é˜¶æ®µï¼Œä»–å°†æ—¥å¿—å†…å®¹è¯»å…¥å†…å­˜åï¼Œåœ¨å†…å­˜ä¸­è¿›è¡Œå›æ”¾æ“ä½œã€‚|
|up:resolve | The MDS enters this state from up:replay if the Ceph file system has multiple ranks (including this one), i.e. it's not a single active MDS cluster. The MDS is resolving any uncommitted inter-MDS operations. All ranks in the file system must be in this state or later for progress to be made, i.e. no rank can be failed/damaged or up:replay. <br><br>ç”¨äºè§£å†³è·¨å¤šä¸ª mds å‡ºç°æƒå¨å…ƒæ•°æ®åˆ†æ­§çš„åœºæ™¯ï¼Œå¯¹äºæœåŠ¡ç«¯åŒ…æ‹¬å­æ ‘åˆ†å¸ƒã€Anchor è¡¨æ›´æ–°ç­‰åŠŸèƒ½ï¼Œå®¢æˆ·ç«¯åŒ…æ‹¬ renameã€unlink ç­‰æ“ä½œã€‚|
|up:reconnect | An MDS enters this state from up:replay or up:resolve. This state is to solicit reconnections from clients. Any client which had a session with this rank must reconnect during this time, configurable via mds_reconnect_timeout.<br><br>æ¢å¤çš„ mds éœ€è¦ä¸ä¹‹å‰çš„å®¢æˆ·ç«¯é‡æ–°å»ºç«‹è¿æ¥ï¼Œå¹¶ä¸”éœ€è¦æŸ¥è¯¢ä¹‹å‰å®¢æˆ·ç«¯å‘å¸ƒçš„æ–‡ä»¶å¥æŸ„ï¼Œé‡æ–°åœ¨ mds çš„ç¼“å­˜ä¸­åˆ›å»ºä¸€è‡´æ€§åŠŸèƒ½å’Œé”çš„çŠ¶æ€ã€‚mds ä¸ä¼šåŒæ­¥è®°å½•æ–‡ä»¶æ‰“å¼€çš„ä¿¡æ¯ï¼ŒåŸå› æ˜¯éœ€è¦é¿å…åœ¨è®¿é—® mds æ—¶äº§ç”Ÿå¤šä½™çš„å»¶è¿Ÿï¼Œå¹¶ä¸”å¤§å¤šæ•°æ–‡ä»¶æ˜¯ä»¥åªè¯»æ–¹å¼æ‰“å¼€ã€‚|
|up:rejoin | The MDS enters this state from up:reconnect. In this state, the MDS is rejoining the MDS cluster cache. In particular, all inter-MDS locks on metadata are reestablished.<br>If there are no known client requests to be replayed, the MDS directly becomes up:active from this state.<br><br>æŠŠå®¢æˆ·ç«¯çš„ inode åŠ è½½åˆ° mds cache |
|up:clientreplay | The MDS may enter this state from up:rejoin. The MDS is replaying any client requests which were replied to but not yet durable (not journaled). Clients resend these requests during up:reconnect and the requests are replayed once again. The MDS enters up:active after completing replay.  |
|down:failed | No MDS actually holds this state. Instead, it is applied to the rank in the file system |
|down:damaged | No MDS actually holds this state. Instead, it is applied to the rank in the file system |
|down:stopped | No MDS actually holds this state. Instead, it is applied to the rank in the file system |

## 12.3 State Diagram

This state diagram shows the possible state transitions for the MDS/rank. The legend is as follows:

### [Color](https://github.com/ceph/ceph/blob/master/doc/cephfs/mds-states.rst#color)

*   ç»¿è‰²: MDS æ˜¯æ´»è·ƒçš„ï¼›
*   æ©™è‰²: MDS å¤„äºè¿‡æ¸¡ä¸´æ—¶çŠ¶æ€ï¼Œè¯•å›¾å˜å¾—æ´»è·ƒï¼›
*   çº¢è‰²:Â  MDS æŒ‡ç¤ºä¸€ä¸ªçŠ¶æ€ï¼Œè¯¥çŠ¶æ€å¯¼è‡´è¢«æ ‡è®°ä¸ºå¤±è´¥ï¼›
*   ç´«è‰²: MDS å’Œ rank ä¸ºåœæ­¢ï¼›
*   çº¢è‰²: MDS æŒ‡ç¤ºä¸€ä¸ªçŠ¶æ€ï¼Œè¯¥çŠ¶æ€å¯¼è‡´è¢«æ ‡è®°ä¸ºæŸåï¼›

### [Shape](https://github.com/ceph/ceph/blob/master/doc/cephfs/mds-states.rst#shape)

*   åœˆï¼šMDS ä¿æŒè¿™ç§çŠ¶æ€ï¼›
*   å…­è¾¹å½¢ï¼šæ²¡æœ‰ MDS ä¿æŒè¿™ä¸ªçŠ¶æ€ï¼›

### [Lines](https://github.com/ceph/ceph/blob/master/doc/cephfs/mds-states.rst#lines)

*   A double-lined shape indicates the rank is "in".

![image.png](https://upload-images.jianshu.io/upload_images/2099201-8c9958250dd4b485.png)

# 13. æ·±å…¥ç ”ç©¶
## 13.1 MDS å¯åŠ¨é˜¶æ®µåˆ†æ

```plain
//src/ceph_mds.cc

int main(int argc, const char **argv)
{
  ceph_pthread_setname(pthread_self(), "ceph-mds");
  vector<const char*> args;
  argv_to_vec(argc, argv, args);
  env_to_vec(args);
  //åˆå§‹åŒ–å…¨å±€ä¿¡æ¯
  auto cct = global_init(NULL, args,
             CEPH_ENTITY_TYPE_MDS, CODE_ENVIRONMENT_DAEMON,
             0, "mds_data");
  //åˆå§‹åŒ–å †æ ˆåˆ†æå™¨
  ceph_heap_profiler_init();
  std::string val, action;
  for (std::vector<const char*>::iterator i = args.begin(); i != args.end(); ) {
    if (ceph_argparse_double_dash(args, i)) {
      break;
    }
    else if (ceph_argparse_flag(args, i, "--help", "-h", (char*)NULL)) {
      // exit(1) will be called in the usage()
      usage();
    }
    else if (ceph_argparse_witharg(args, i, &val, "--hot-standby", (char*)NULL)) {
      int r = parse_rank("hot-standby", val);
      dout(0) << "requesting standby_replay for mds." << r << dendl;
      char rb[32];
      snprintf(rb, sizeof(rb), "%d", r);
      g_conf->set_val("mds_standby_for_rank", rb);
      g_conf->set_val("mds_standby_replay", "true");
      g_conf->apply_changes(NULL);
    }
    else {
      derr << "Error: can't understand argument: " << *i << "\n" << dendl;
      usage();
    }
  }
  pick_addresses(g_ceph_context, CEPH_PICK_ADDRESS_PUBLIC);
  // Normal startup
  if (g_conf->name.has_default_id()) {
    derr << "must specify '-i name' with the ceph-mds instance name" << dendl;
    usage();
  }
  if (g_conf->name.get_id().empty() ||
      (g_conf->name.get_id()[0] >= '0' && g_conf->name.get_id()[0] <= '9')) {
    derr << "deprecation warning: MDS id '" << g_conf->name
      << "' is invalid and will be forbidden in a future version.  "
      "MDS names may not start with a numeric digit." << dendl;
  }
  uint64_t nonce = 0;
  get_random_bytes((char*)&nonce, sizeof(nonce));
  std::string public_msgr_type = g_conf->ms_public_type.empty() ? g_conf->get_val<std::string>("ms_type") : g_conf->ms_public_type;
  //åˆ›å»ºé€šä¿¡çš„messenger
  Messenger *msgr = Messenger::create(g_ceph_context, public_msgr_type,
                      entity_name_t::MDS(-1), "mds",
                      nonce, Messenger::HAS_MANY_CONNECTIONS);
  if (!msgr)
    exit(1);
  msgr->set_cluster_protocol(CEPH_MDS_PROTOCOL);
  cout << "starting " << g_conf->name << " at " << msgr->get_myaddr()
       << std::endl;
  uint64_t required =
    CEPH_FEATURE_OSDREPLYMUX;
  msgr->set_default_policy(Messenger::Policy::lossy_client(required));
  msgr->set_policy(entity_name_t::TYPE_MON,
                   Messenger::Policy::lossy_client(CEPH_FEATURE_UID |
                                                   CEPH_FEATURE_PGID64));
  msgr->set_policy(entity_name_t::TYPE_MDS,
                   Messenger::Policy::lossless_peer(CEPH_FEATURE_UID));
  msgr->set_policy(entity_name_t::TYPE_CLIENT,
                   Messenger::Policy::stateful_server(0));
  int r = msgr->bind(g_conf->public_addr);
  if (r < 0)
    exit(1);
  global_init_daemonize(g_ceph_context);
  common_init_finish(g_ceph_context);
  // get monmap
  MonClient mc(g_ceph_context);
  if (mc.build_initial_monmap() < 0)
    return -1;
  global_init_chdir(g_ceph_context);
  //å¼€å§‹æ¥æ”¶æ¶ˆæ¯
  msgr->start();

  //åˆ›å»ºMDSDaemonï¼Œå¯åŠ¨MDS
  mds = new MDSDaemon(g_conf->name.get_id().c_str(), msgr, &mc);
  // in case we have to respawn...
  mds->orig_argc = argc;
  mds->orig_argv = argv;
  r = mds->init();
  if (r < 0) {
    msgr->wait();
    goto shutdown;
  }
  ...
  msgr->wait();

  ...
  return 0;
}
```

## 13.2 MDS æ ¸å¿ƒç»„ä»¶
![image.png](https://upload-images.jianshu.io/upload_images/2099201-f771aab728be958f.png)

## 13.3 MDSDaemon ç±»å›¾
![image.png](https://upload-images.jianshu.io/upload_images/2099201-71360f36b481af69.png)


## 13.4  MDSDaemon æºç åˆ†æ

```plain
//MDSDaemon.cc

/***************************admin socketç›¸å…³ï¼Œç»Ÿè®¡mdsåŸ‹ç‚¹ä¿¡æ¯åŠçŠ¶æ€ä¿¡æ¯***************************/
bool MDSDaemon::asok_command(string command, cmdmap_t& cmdmap, string format,
            ostream& ss);
void MDSDaemon::dump_status(Formatter *f);
void MDSDaemon::set_up_admin_socket();
void MDSDaemon::clean_up_admin_socket()
/*********************************************************************************************/


/***************************åˆå§‹åŒ–***************************/
int MDSDaemon::init()
{
  ...
  //åˆå§‹åŒ–MonClient
  int r = 0;
  r = monc->init();
  if (r < 0) {
    derr << "ERROR: failed to get monmap: " << cpp_strerror(-r) << dendl;
    mds_lock.Lock();
    suicide();
    mds_lock.Unlock();
    return r;
  }
  ...


  //åˆå§‹åŒ–mgrclient
  mgrc.init();
  messenger->add_dispatcher_head(&mgrc);
  mds_lock.Lock();
  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE) {
    dout(4) << __func__ << ": terminated already, dropping out" << dendl;
    mds_lock.Unlock();
    return 0;
  }
  monc->sub_want("mdsmap", 0, 0);
  monc->sub_want("mgrmap", 0, 0);
  monc->renew_subs();
  mds_lock.Unlock();

  //åˆå§‹åŒ–SaftTimer
  timer.init();

  //åˆå§‹åŒ–Beacon
  beacon.init(mdsmap);
  messenger->set_myname(entity_name_t::MDS(MDS_RANK_NONE));

  // é‡ç½®tick
  reset_tick();
  mds_lock.Unlock();
  return 0;
}
/*********************************************************/


/***************************é‡ç½®tickç›¸å…³***************************/
void MDSDaemon::reset_tick();
void MDSDaemon::tick();
/****************************************************************/

/***************************å¤„ç†å‘½ä»¤ï¼Œè¿”å›ä¿¡æ¯***************************/
void MDSDaemon::handle_command(MCommand *m)ï¼›
void MDSDaemon::send_command_reply(MCommand *m, MDSRank *mds_rank,
                   int r, bufferlist outbl,
                   boost::string_view outs);
//mds mapä¿¡æ¯
void MDSDaemon::handle_mds_map(MMDSMap *m);
/*********************************************************************/

/***************************å¤„ç†ä¿¡å·ï¼Œè‡ªæ€ï¼Œé‡ç”Ÿ*************************/
void MDSDaemon::handle_signal(int signum);
void MDSDaemon::suicide();
void MDSDaemon::respawn()ï¼›
/********************************************************************/

/***************************æ¶ˆæ¯è°ƒåº¦å¤„ç†*************************/
bool MDSDaemon::ms_dispatch(Message *m)
{
  Mutex::Locker l(mds_lock);
  if (stopping) {
    return false;
  }
  //mdså¤„äºshutdownçŠ¶æ€ï¼Œä¸å¤„ç†æ¶ˆæ¯
  if (beacon.get_want_state() == CEPH_MDS_STATE_DNE) {
    dout(10) << " stopping, discarding " << *m << dendl;
    m->put();
    return true;
  }
  // ä¼˜å…ˆå¤„ç†daemon message
  const bool handled_core = handle_core_message(m);
  if (handled_core) {
    return true;
  }
  // ä¸æ˜¯æ ¸å¿ƒçš„ï¼Œå°è¯•ç»™rankå‘é€æ¶ˆæ¯
  if (mds_rank) {
    return mds_rank->ms_dispatch(m);
  } else {
    return false;
  }
}

//é«˜ä¼˜å…ˆçº§å¤„ç†çš„æ¶ˆæ¯MON,MDS,OSD
bool MDSDaemon::handle_core_message(Message *m)
{
  switch (m->get_type()) {
    // MON
  case CEPH_MSG_MON_MAP:
    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON);
    m->put();
    break;
    // MDS
  case CEPH_MSG_MDS_MAP:
    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON | CEPH_ENTITY_TYPE_MDS);
    handle_mds_map(static_cast<MMDSMap*>(m));
    break;
    // OSD
  case MSG_COMMAND:
    handle_command(static_cast<MCommand*>(m));
    break;
  case CEPH_MSG_OSD_MAP:
    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON | CEPH_ENTITY_TYPE_OSD);
    if (mds_rank) {
      mds_rank->handle_osd_map();
    }
    m->put();
    break;
  case MSG_MON_COMMAND:
    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MON);
    clog->warn() << "dropping `mds tell` command from legacy monitor";
    m->put();
    break;
  default:
    return false;
  }
  return true;
}
//é‡ç½®æ¶ˆæ¯ï¼Œä¸è¿›è¡Œå¤„ç†
bool MDSDaemon::ms_handle_reset(Connection *con);
void MDSDaemon::ms_handle_remote_reset(Connection *con);
bool MDSDaemon::ms_handle_refused(Connection *con)
/***************************************************************/

/***************************authæ¨¡å—*************************/
//monç”Ÿæˆauth
bool MDSDaemon::ms_get_authorizer(int dest_type, AuthAuthorizer **authorizer, bool force_new);
//éªŒè¯æˆæƒ
bool MDSDaemon::ms_verify_authorizer(Connection *con, int peer_type,
                   int protocol, bufferlist& authorizer_data, bufferlist& authorizer_reply,
                     bool& is_valid, CryptoKey& session_key,
                     std::unique_ptr<AuthAuthorizerChallenge> *challenge);
/**************************************************************/

/***************************session è¿æ¥accept*************************/
void MDSDaemon::ms_handle_accept(Connection *con)
{
  Mutex::Locker l(mds_lock);
  if (stopping) {
    return;
  }
  Session *s = static_cast<Session *>(con->get_priv());
  dout(10) << "ms_handle_accept " << con->get_peer_addr() << " con " << con << " session " << s << dendl;
  if (s) {
    if (s->connection != con) {
      dout(10) << " session connection " << s->connection << " -> " << con << dendl;
      s->connection = con;
      // send out any queued messages
      while (!s->preopen_out_queue.empty()) {
    con->send_message(s->preopen_out_queue.front());
    s->preopen_out_queue.pop_front();
      }
    }
    s->put();
  }
}
/*************************************************************/

/***************************clean shutdown*************************/
bool MDSDaemon::is_clean_shutdown()
{
  if (mds_rank) {
    return mds_rank->is_stopped();
  } else {
    return true;
  }
}
/************************************************************/
```

## 13.5 MDSRank ç±»å›¾
![image.png](https://upload-images.jianshu.io/upload_images/2099201-a1297d64d19229c0.png)

## 13.6 MDSRank æºç åˆ†æ

```plain
//MDSRank.cc

/***************************initåˆå§‹åŒ–***************************/
void MDSRankDispatcher::init()
{
  //Objecteråˆå§‹åŒ–ï¼Œå¹¶ä¸”æ·»åŠ åˆ°æ¶ˆæ¯å¤´éƒ¨ï¼Œç„¶åå¯åŠ¨
  objecter->init();
  messenger->add_dispatcher_head(objecter);
  objecter->start();

  //æ›´æ–°é…ç½®æ–‡ä»¶ä¸­logé…ç½®ä¿¡æ¯
  update_log_config();
  create_logger();

  handle_osd_map();
  progress_thread.create("mds_rank_progr");
  purge_queue.init();
  finisher->start();
}
/***************************************************************/

/***************************tick***************************/
void MDSRankDispatcher::tick()
{
  //é‡ç½®heartbeatè¶…æ—¶æ—¶é—´ï¼Œé¿å…è¢«monitor kill
  heartbeat_reset();
  if (beacon.is_laggy()) {
    dout(5) << "tick bailing out since we seem laggy" << dendl;
    return;
  }
  //ä»op_trackerä¸­è¯»å–åˆ°æ‰€æœ‰in_flightçš„æ“ä½œåç§°
  check_ops_in_flight();
  //å”¤é†’progress_threadçº¿ç¨‹
  progress_thread.signal();
  // make sure mds log flushes, trims periodically
  mdlog->flush();
  //å¦‚æœæ˜¯active,stoppingå»é™¤cache,client_leases,log
  if (is_active() || is_stopping()) {
    mdcache->trim();
    mdcache->trim_client_leases();
    mdcache->check_memory_usage();
    mdlog->trim();  // NOT during recovery!
  }
  // æ›´æ–°log
  if (logger) {
    logger->set(l_mds_subtrees, mdcache->num_subtrees());
    mdcache->log_stat();
  }
  // ...
  if (is_clientreplay() || is_active() || is_stopping()) {
    server->find_idle_sessions();
    locker->tick();
  }
  //å¦‚æœå¤„äºreconnect æ ‡è®°
  if (is_reconnect())
    server->reconnect_tick();
  if (is_active()) {
    balancer->tick();
    mdcache->find_stale_fragment_freeze();
    mdcache->migrator->find_stale_export_freeze();
    if (snapserver)
      snapserver->check_osd_map(false);
  }
  if (is_active() || is_stopping()) {
    update_targets(ceph_clock_now());
  }
  // shut down?
  if (is_stopping()) {
    mdlog->trim();
    if (mdcache->shutdown_pass()) {
      uint64_t pq_progress = 0 ;
      uint64_t pq_total = 0;
      size_t pq_in_flight = 0;
      if (!purge_queue.drain(&pq_progress, &pq_total, &pq_in_flight)) {
        dout(7) << "shutdown_pass=true, but still waiting for purge queue"
                << dendl;
        // This takes unbounded time, so we must indicate progress
        // to the administrator: we do it in a slightly imperfect way
        // by sending periodic (tick frequency) clog messages while
        // in this state.
        clog->info() << "MDS rank " << whoami << " waiting for purge queue ("
          << std::dec << pq_progress << "/" << pq_total << " " << pq_in_flight
          << " files purging" << ")";
      } else {
        dout(7) << "shutdown_pass=true, finished w/ shutdown, moving to "
                   "down:stopped" << dendl;
        stopping_done();
      }
    }
    else {
      dout(7) << "shutdown_pass=false" << dendl;
    }
  }
  // Expose ourselves to Beacon to update health indicators
  beacon.notify_health(this);
}
/***********************************************************/

/***************************shutdown***************************/
void MDSRankDispatcher::shutdown()
{
  // It should never be possible for shutdown to get called twice, because
  // anyone picking up mds_lock checks if stopping is true and drops
  // out if it is.
  assert(stopping == false);
  stopping = true;
  dout(1) << __func__ << ": shutting down rank " << whoami << dendl;
  //å…³é—­å®šæ—¶å™¨
  timer.shutdown();
  //å…³é—­mdlog
  mdlog->shutdown();
  //å…³é—­mdcache
  mdcache->shutdown();
  purge_queue.shutdown();
  mds_lock.Unlock();
  finisher->stop(); // no flushing
  mds_lock.Lock();
  //å…³é—­objecter
  if (objecter->initialized)
    objecter->shutdown();
  //å…³é—­monclient
  monc->shutdown();
  //å…³é—­op_tracker
  op_tracker.on_shutdown();
  //å…³é—­progress_thread
  progress_thread.shutdown();
  // release mds_lock for finisher/messenger threads (e.g.
  // MDSDaemon::ms_handle_reset called from Messenger).
  mds_lock.Unlock();
  //å…³é—­messenger
  messenger->shutdown();
  mds_lock.Lock();
  //åˆ é™¤handle
  if (hb) {
    g_ceph_context->get_heartbeat_map()->remove_worker(hb);
    hb = NULL;
  }
}
/***********************************************************/

/*****************************admin socket asok******************************/
bool MDSRankDispatcher::handle_asok_command();
//å‰”é™¤ç”¨æˆ·
void MDSRankDispatcher::evict_clients(const SessionFilter &filter, MCommand *m);
bool MDSRank::evict_client(int64_t session_id, bool wait, bool blacklist, std::stringstream& err_ss,Context *on_killed);
//dumpç”¨æˆ·session
void MDSRankDispatcher::dump_sessions(const SessionFilter &filter, Formatter *f);
void MDSRankDispatcher::update_log_config();
Session *MDSRank::get_session(Message *m);
void MDSRank::command_scrub_path(Formatter *f, boost::string_view path, vector<string>& scrubop_vec);
void MDSRank::command_tag_path(Formatter *f, boost::string_view path, boost::string_view tag);
void MDSRank::command_flush_path(Formatter *f, boost::string_view path);
void MDSRank::command_flush_journal(Formatter *f);
void MDSRank::command_get_subtrees(Formatter *f);
void MDSRank::command_export_dir(Formatter *f, boost::string_view path, mds_rank_t target);
bool MDSRank::command_dirfrag_split(cmdmap_t cmdmap, std::ostream &ss);
bool MDSRank::command_dirfrag_merge(cmdmap_t cmdmap, std::ostream &ss);
bool MDSRank::command_dirfrag_ls(cmdmap_t cmdmap, std::ostream &ss, Formatter *f);
void MDSRank::dump_status(Formatter *f);
void MDSRank::dump_clientreplay_status(Formatter *f);
void MDSRank::create_logger();
/***************************************************************************/

/*****************************æ¶ˆæ¯åˆ†å‘è°ƒåº¦******************************/
bool MDSRankDispatcher::ms_dispatch(Message *m);
bool MDSRank::_dispatch(Message *m, bool new_msg)
{
  //å¦‚æœmessageä¸æ˜¯mdså‘é€è¿‡æ¥,åˆ™ç›´æ¥è¿”å›
  if (is_stale_message(m)) {
    m->put();
    return true;
  }
  //å¦‚æœmdså¤„äºlaggyçŠ¶æ€ï¼Œå°†æ¶ˆæ¯æ”¾å…¥waiting_for_nolaggyæ•°ç»„
  if (beacon.is_laggy()) {
    dout(10) << " laggy, deferring " << *m << dendl;
    waiting_for_nolaggy.push_back(m);
  }
  //å¦‚æœæ¶ˆæ¯æ˜¯æ–°æ¶ˆæ¯å¹¶ä¸”waiting_for_nolaggyæ•°ç»„ä¸ä¸ºç©ºï¼Œ åˆ™æ”¾å…¥waiting_for_nolaggyä¸­
  else if (new_msg && !waiting_for_nolaggy.empty()) {
    dout(10) << " there are deferred messages, deferring " << *m << dendl;
    waiting_for_nolaggy.push_back(m);
  } else {
    if (!handle_deferrable_message(m)) {
      dout(0) << "unrecognized message " << *m << dendl;
      return false;
    }
    heartbeat_reset();
  }
  ...
  //å¦‚æœmdså¤„äºlaggyçŠ¶æ€,åˆ™ç›´æ¥è¿”å›
  if (beacon.is_laggy()) {
    // We've gone laggy during dispatch, don't do any
    // more housekeeping
    return true;
  }
  // done with all client replayed requests?
  if (is_clientreplay() &&
      mdcache->is_open() &&
      replay_queue.empty() &&
      beacon.get_want_state() == MDSMap::STATE_CLIENTREPLAY) {
    int num_requests = mdcache->get_num_client_requests();
    dout(10) << " still have " << num_requests << " active replay requests" << dendl;
    if (num_requests == 0)
      clientreplay_done();
  }
  ...
  update_mlogger();
  return true;
}
//å»¶æœŸå¾…å¤„ç†çš„æ¶ˆæ¯
bool MDSRank::handle_deferrable_message(Message *m)
{
  int port = m->get_type() & 0xff00;
  switch (port) {
  //cacheç±»å‹æ¶ˆæ¯ï¼Œç”±mdcacheå¤„ç†
  case MDS_PORT_CACHE:
    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MDS);
    mdcache->dispatch(m);
    break;
  //migratorç±»å‹æ¶ˆæ¯ï¼Œç”±migratorå¤„ç†
  case MDS_PORT_MIGRATOR:
    ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MDS);
    mdcache->migrator->dispatch(m);
    break;
  default:
    //client session,slaveæ¶ˆæ¯ï¼Œç”±serverå¤„ç†
    switch (m->get_type()) {
      // SERVER
    case CEPH_MSG_CLIENT_SESSION:
    case CEPH_MSG_CLIENT_RECONNECT:
      ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_CLIENT);
      // fall-thru
    case CEPH_MSG_CLIENT_REQUEST:
      server->dispatch(m);
      break;
    case MSG_MDS_SLAVE_REQUEST:
      ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MDS);
      server->dispatch(m);
      break;
    //heartbeatæ¶ˆæ¯ï¼Œæœ‰balancerå¤„ç†
    case MSG_MDS_HEARTBEAT:
      ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MDS);
      balancer->proc_message(m);
      break;
    case MSG_MDS_TABLE_REQUEST:
      ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MDS);
      {
    MMDSTableRequest *req = static_cast<MMDSTableRequest*>(m);
    if (req->op < 0) {
      MDSTableClient *client = get_table_client(req->table);
          client->handle_request(req);
    } else {
      MDSTableServer *server = get_table_server(req->table);
      server->handle_request(req);
    }
      }
      break;
    //lockæ¶ˆæ¯ï¼Œç”±lockerå¤„ç†
    case MSG_MDS_LOCK:
    case MSG_MDS_INODEFILECAPS:
      ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_MDS);
      locker->dispatch(m);
      break;
    //client capsæ¶ˆæ¯ï¼Œç”±lockerå¤„ç†
    case CEPH_MSG_CLIENT_CAPS:
    case CEPH_MSG_CLIENT_CAPRELEASE:
    case CEPH_MSG_CLIENT_LEASE:
      ALLOW_MESSAGES_FROM(CEPH_ENTITY_TYPE_CLIENT);
      locker->dispatch(m);
      break;
    default:
      return false;
    }
  }
  return true;
}
void MDSRank::_advance_queues();
void MDSRank::heartbeat_reset();
/******************************************************************/

/*****************************æ¶ˆæ¯å‘é€******************************/
void MDSRank::send_message(Message *m, Connection *c);
void MDSRank::send_message_mds(Message *m, mds_rank_t mds);
void MDSRank::forward_message_mds(Message *m, mds_rank_t mds);
void MDSRank::send_message_client_counted(Message *m, client_t client);
void MDSRank::send_message_client_counted(Message *m, Connection *connection);
void MDSRank::send_message_client_counted(Message *m, Session *session);
void MDSRank::send_message_client(Message *m, Session *session);
/******************************************************************/

/*****************************ç±»æˆå‘˜ç›¸å…³******************************/
int64_t MDSRank::get_metadata_pool();
MDSTableClient *MDSRank::get_table_client(int t);
MDSTableServer *MDSRank::get_table_server(int t);
utime_t MDSRank::get_laggy_until();
void MDSRank::request_state(MDSMap::DaemonState s);
/*******************************************************************/

/*****************************MDSRankçŠ¶æ€ç›¸å…³******************************/
//è‡ªæ€
void MDSRank::suicide();
//é‡ç”Ÿ
void MDSRank::respawn();
//æŸå
void MDSRank::damaged();
void MDSRank::damaged_unlocked();

void MDSRank::handle_write_error(int err)
{
  //å¦‚æœé”™è¯¯ä¸º-EBLACKLISTEDï¼Œåˆ™é‡å¯MDS
  if (err == -EBLACKLISTED) {
    derr << "we have been blacklisted (fenced), respawning..." << dendl;
    respawn();
    return;
  }
  //å¦‚æœmds_action_on_write_errorå¤§äºç­‰äº2ï¼Œåˆ™é‡å¯MDS
  if (g_conf->mds_action_on_write_error >= 2) {
    derr << "unhandled write error " << cpp_strerror(err) << ", suicide..." << dendl;
    respawn();
  } else if (g_conf->mds_action_on_write_error == 1) {
    derr << "unhandled write error " << cpp_strerror(err) << ", force readonly..." << dendl;
    mdcache->force_readonly();
  } else {
    // ignore;
    derr << "unhandled write error " << cpp_strerror(err) << ", ignore..." << dendl;
  }
}
//æ¶ˆæ¯æ˜¯å¦æ¥ç€mds
bool MDSRank::is_stale_message(Message *m);
/********************************************************************/

/*****************************ProgressThreadç›¸å…³******************************/
void *MDSRank::ProgressThread::entry();
void MDSRank::ProgressThread::shutdown();
/***************************************************************************/

/*****************************bootç›¸å…³******************************/
void MDSRank::boot_start(BootStep step, int r);
void MDSRank::validate_sessions();
void MDSRank::starting_done();
void MDSRank::boot_create();
oid MDSRank::creating_done();
/*****************************bootç›¸å…³******************************/

/*****************************replayç›¸å…³******************************/
void MDSRank::calc_recovery_set();
void MDSRank::replay_start();
void MDSRank::_standby_replay_restart_finish(int r, uint64_t old_read_pos);
void MDSRank::standby_replay_restart();
void MDSRank::replay_done();
/*******************************************************************/

/*****************************resolveç›¸å…³******************************/
void MDSRank::reopen_log();
void MDSRank::resolve_start();
void MDSRank::resolve_done();
/*********************************************************************/

/*****************************reconnectç›¸å…³******************************/
void MDSRank::reconnect_start();
void MDSRank::reconnect_done();
/***********************************************************************/

/*****************************rejoinç›¸å…³******************************/
void MDSRank::rejoin_joint_start();
void MDSRank::rejoin_start();
void MDSRank::rejoin_done();
/********************************************************************/

/*****************************clientreplayç›¸å…³******************************/
void MDSRank::clientreplay_start();
bool MDSRank::queue_one_replay();
void MDSRank::clientreplay_done();
/*************************************************************************/

/*****************************activeç›¸å…³******************************/
void MDSRank::active_start();
/********************************************************************/

/*****************************recoveryç›¸å…³******************************/
oid MDSRank::recovery_done(int oldstate);
/**********************************************************************/

/*****************************creating_ç›¸å…³******************************/
void MDSRank::creating_done();
/***********************************************************************/

/*****************************stoppingç›¸å…³******************************/
void MDSRank::stopping_start();
void MDSRank::stopping_done();
/**********************************************************************/

/*****************************handle_mds_mapç›¸å…³******************************/
void MDSRankDispatcher::handle_mds_map(MMDSMap *m, MDSMap *oldmap);
void MDSRank::handle_mds_recovery(mds_rank_t who);
void MDSRank::handle_mds_failure(mds_rank_t who);
 /***************************************************************************/
```

# ä½œè€…ä¿¡æ¯
**ä½œè€…ï¼š** æèˆª

**ä¸ªäººç®€ä»‹ï¼š** å¤šå¹´çš„åº•å±‚å¼€å‘ç»éªŒï¼Œåœ¨é«˜æ€§èƒ½ nginx å¼€å‘å’Œåˆ†å¸ƒå¼ç¼“å­˜ redis cluster æœ‰ç€ä¸°å¯Œçš„ç»éªŒï¼Œç›®å‰ä»äº‹ Ceph å·¥ä½œã€‚
å…ˆååœ¨ 58 åŒåŸã€æ±½è½¦ä¹‹å®¶ã€ä¼˜é…·åœŸè±†é›†å›¢å·¥ä½œã€‚
ç›®å‰ä¾›èŒäºæ»´æ»´åŸºç¡€å¹³å°-æŠ€æœ¯ä¸“å®¶å²—ä½   ä¸»è¦è´Ÿè´£åˆ†å¸ƒå¼ Ceph ç³»ç»Ÿã€‚
ä¸ªäººä¸»è¦å…³æ³¨çš„æŠ€æœ¯é¢†åŸŸï¼šé«˜æ€§èƒ½ Nginx å¼€å‘ã€åˆ†å¸ƒå¼ç¼“å­˜ã€åˆ†å¸ƒå¼å­˜å‚¨ã€‚
