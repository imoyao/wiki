---
title: CEPH ä»‹ç»ä¹‹ PG çŠ¶æ€è¯¦è§£

categories: 
  - ğŸ’» å·¥ä½œ
  - å­˜å‚¨
  - CEPH
  - åŸºæœ¬åŸç†
date: 2020-05-23 11:02:28
tags: null
permalink: /pages/71eeff/
---

# 1. PG ä»‹ç»
ç»§ä¸Šæ¬¡åˆ†äº«çš„[ã€ŠCeph ä»‹ç»åŠåŸç†æ¶æ„åˆ†äº«ã€‹](https://www.jianshu.com/p/cc3ece850433)ï¼Œè¿™æ¬¡ä¸»è¦æ¥åˆ†äº« Ceph ä¸­çš„ PG å„ç§çŠ¶æ€è¯¦è§£ï¼ŒPG æ˜¯æœ€å¤æ‚å’Œéš¾äºç†è§£çš„æ¦‚å¿µä¹‹ä¸€ï¼ŒPG çš„å¤æ‚å¦‚ä¸‹ï¼š
 - åœ¨æ¶æ„å±‚æ¬¡ä¸Šï¼ŒPG ä½äº RADOS å±‚çš„ä¸­é—´ã€‚
     a. å¾€ä¸Šè´Ÿè´£æ¥æ”¶å’Œå¤„ç†æ¥è‡ªå®¢æˆ·ç«¯çš„è¯·æ±‚ã€‚
     b. å¾€ä¸‹è´Ÿè´£å°†è¿™äº›æ•°æ®è¯·æ±‚ç¿»è¯‘ä¸ºèƒ½å¤Ÿè¢«æœ¬åœ°å¯¹è±¡å­˜å‚¨æ‰€èƒ½ç†è§£çš„äº‹åŠ¡ã€‚
 - æ˜¯ç»„æˆå­˜å‚¨æ± çš„åŸºæœ¬å•ä½ï¼Œå­˜å‚¨æ± ä¸­çš„å¾ˆå¤šç‰¹æ€§ï¼Œéƒ½æ˜¯ç›´æ¥ä¾æ‰˜äº PG å®ç°çš„ã€‚
 - é¢å‘å®¹ç¾åŸŸçš„å¤‡ä»½ç­–ç•¥ä½¿å¾—ä¸€èˆ¬è€Œè¨€çš„ PG éœ€è¦æ‰§è¡Œè·¨èŠ‚ç‚¹çš„åˆ†å¸ƒå¼å†™ï¼Œå› æ­¤æ•°æ®åœ¨ä¸åŒèŠ‚ç‚¹ä¹‹é—´çš„åŒæ­¥ã€æ¢å¤æ—¶çš„æ•°æ®ä¿®å¤ä¹Ÿéƒ½æ˜¯ä¾èµ– PG å®Œæˆã€‚


# 2. PG çŠ¶æ€è¡¨
æ­£å¸¸çš„ PG çŠ¶æ€æ˜¯ 100%çš„ active + cleanï¼Œ è¿™è¡¨ç¤ºæ‰€æœ‰çš„ PG æ˜¯å¯è®¿é—®çš„ï¼Œæ‰€æœ‰å‰¯æœ¬éƒ½å¯¹å…¨éƒ¨ PG éƒ½å¯ç”¨ã€‚
å¦‚æœ Ceph ä¹ŸæŠ¥å‘Š PG çš„å…¶ä»–çš„è­¦å‘Šæˆ–è€…é”™è¯¯çŠ¶æ€ã€‚PG çŠ¶æ€è¡¨ï¼š

| çŠ¶æ€   |      æè¿°      |
|----------|---------------|
| Activating |  Peering å·²ç»å®Œæˆï¼ŒPG æ­£åœ¨ç­‰å¾…æ‰€æœ‰ PG å®ä¾‹åŒæ­¥å¹¶å›ºåŒ– Peering çš„ç»“æœ(Infoã€Log ç­‰)  |
| Active | æ´»è·ƒæ€ã€‚PG å¯ä»¥æ­£å¸¸å¤„ç†æ¥è‡ªå®¢æˆ·ç«¯çš„è¯»å†™è¯·æ±‚ |
| Backfilling | æ­£åœ¨åå°å¡«å……æ€ã€‚ backfill æ˜¯ recovery çš„ä¸€ç§ç‰¹æ®Šåœºæ™¯ï¼ŒæŒ‡ peering å®Œæˆåï¼Œå¦‚æœåŸºäºå½“å‰æƒå¨æ—¥å¿—æ— æ³•å¯¹ Up Set å½“ä¸­çš„æŸäº› PG å®ä¾‹å®æ–½å¢é‡åŒæ­¥(ä¾‹å¦‚æ‰¿è½½è¿™äº› PG å®ä¾‹çš„ OSD ç¦»çº¿å¤ªä¹…ï¼Œæˆ–è€…æ˜¯æ–°çš„ OSD åŠ å…¥é›†ç¾¤å¯¼è‡´çš„ PG å®ä¾‹æ•´ä½“è¿ç§») åˆ™é€šè¿‡å®Œå…¨æ‹·è´å½“å‰ Primary æ‰€æœ‰å¯¹è±¡çš„æ–¹å¼è¿›è¡Œå…¨é‡åŒæ­¥ |
| Backfill-toofull | æŸä¸ªéœ€è¦è¢« Backfill çš„ PG å®ä¾‹ï¼Œå…¶æ‰€åœ¨çš„ OSD å¯ç”¨ç©ºé—´ä¸è¶³ï¼ŒBackfill æµç¨‹å½“å‰è¢«æŒ‚èµ· |
| Backfill-wait| ç­‰å¾… Backfill èµ„æºé¢„ç•™ |
| Clean | å¹²å‡€æ€ã€‚PG å½“å‰ä¸å­˜åœ¨å¾…ä¿®å¤çš„å¯¹è±¡ï¼Œ Acting Set å’Œ Up Set å†…å®¹ä¸€è‡´ï¼Œå¹¶ä¸”å¤§å°ç­‰äºå­˜å‚¨æ± çš„å‰¯æœ¬æ•° |
| Creating | PG æ­£åœ¨è¢«åˆ›å»º |
| Deep | PG æ­£åœ¨æˆ–è€…å³å°†è¿›è¡Œå¯¹è±¡ä¸€è‡´æ€§æ‰«ææ¸…æ´— |
| Degraded | é™çº§çŠ¶æ€ã€‚Peering å®Œæˆåï¼ŒPG æ£€æµ‹åˆ°ä»»æ„ä¸€ä¸ª PG å®ä¾‹å­˜åœ¨ä¸ä¸€è‡´(éœ€è¦è¢«åŒæ­¥/ä¿®å¤)çš„å¯¹è±¡ï¼Œæˆ–è€…å½“å‰ ActingSet å°äºå­˜å‚¨æ± å‰¯æœ¬æ•° |
| Down | Peering è¿‡ç¨‹ä¸­ï¼ŒPG æ£€æµ‹åˆ°æŸä¸ªä¸èƒ½è¢«è·³è¿‡çš„ Interval ä¸­(ä¾‹å¦‚è¯¥ Interval æœŸé—´ï¼ŒPG å®Œæˆäº† Peeringï¼Œå¹¶ä¸”æˆåŠŸåˆ‡æ¢è‡³ Active çŠ¶æ€ï¼Œä»è€Œæœ‰å¯èƒ½æ­£å¸¸å¤„ç†äº†æ¥è‡ªå®¢æˆ·ç«¯çš„è¯»å†™è¯·æ±‚),å½“å‰å‰©ä½™åœ¨çº¿çš„ OSD ä¸è¶³ä»¥å®Œæˆæ•°æ®ä¿®å¤  |
| Incomplete | Peering è¿‡ç¨‹ä¸­ï¼Œ ç”±äº a. æ— éé€‰å‡ºæƒå¨æ—¥å¿— b. é€šè¿‡ choose_acting é€‰å‡ºçš„ Acting Set åç»­ä¸è¶³ä»¥å®Œæˆæ•°æ®ä¿®å¤ï¼Œå¯¼è‡´ Peering æ— éæ­£å¸¸å®Œæˆ |
| Inconsistent | ä¸ä¸€è‡´æ€ã€‚é›†ç¾¤æ¸…ç†å’Œæ·±åº¦æ¸…ç†åæ£€æµ‹åˆ° PG ä¸­çš„å¯¹è±¡åœ¨å‰¯æœ¬å­˜åœ¨ä¸ä¸€è‡´ï¼Œä¾‹å¦‚å¯¹è±¡çš„æ–‡ä»¶å¤§å°ä¸ä¸€è‡´æˆ– Recovery ç»“æŸåä¸€ä¸ªå¯¹è±¡çš„å‰¯æœ¬ä¸¢å¤± |
| Peered | Peering å·²ç»å®Œæˆï¼Œä½†æ˜¯ PG å½“å‰ ActingSet è§„æ¨¡å°äºå­˜å‚¨æ± è§„å®šçš„æœ€å°å‰¯æœ¬æ•°(min_size) |
| Peering | æ­£åœ¨åŒæ­¥æ€ã€‚PG æ­£åœ¨æ‰§è¡ŒåŒæ­¥å¤„ç† |
| Recovering | æ­£åœ¨æ¢å¤æ€ã€‚é›†ç¾¤æ­£åœ¨æ‰§è¡Œè¿ç§»æˆ–åŒæ­¥å¯¹è±¡å’Œä»–ä»¬çš„å‰¯æœ¬ |
| Recovering-wait | ç­‰å¾… Recovery èµ„æºé¢„ç•™ |
| Remapped | é‡æ–°æ˜ å°„æ€ã€‚PG æ´»åŠ¨é›†ä»»ä½•çš„ä¸€ä¸ªæ”¹å˜ï¼Œæ•°æ®å‘ç”Ÿä»è€æ´»åŠ¨é›†åˆ°æ–°æ´»åŠ¨é›†çš„è¿ç§»ã€‚åœ¨è¿ç§»æœŸé—´è¿˜æ˜¯ç”¨è€çš„æ´»åŠ¨é›†ä¸­çš„ä¸» OSD å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚ï¼Œä¸€æ—¦è¿ç§»å®Œæˆæ–°æ´»åŠ¨é›†ä¸­çš„ä¸» OSD å¼€å§‹å¤„ç† |
| Repair | PG åœ¨æ‰§è¡Œ Scrub è¿‡ç¨‹ä¸­ï¼Œå¦‚æœå‘ç°å­˜åœ¨ä¸ä¸€è‡´çš„å¯¹è±¡ï¼Œå¹¶ä¸”èƒ½å¤Ÿä¿®å¤ï¼Œåˆ™è‡ªåŠ¨è¿›è¡Œä¿®å¤çŠ¶æ€ |
| Scrubbing | PG æ­£åœ¨æˆ–è€…å³å°†è¿›è¡Œå¯¹è±¡ä¸€è‡´æ€§æ‰«æ |
| Unactive | éæ´»è·ƒæ€ã€‚PG ä¸èƒ½å¤„ç†è¯»å†™è¯·æ±‚ |
| Unclean | éå¹²å‡€æ€ã€‚PG ä¸èƒ½ä»ä¸Šä¸€ä¸ªå¤±è´¥ä¸­æ¢å¤ |
| Stale | æœªåˆ·æ–°æ€ã€‚PG çŠ¶æ€æ²¡æœ‰è¢«ä»»ä½• OSD æ›´æ–°ï¼Œè¿™è¯´æ˜æ‰€æœ‰å­˜å‚¨è¿™ä¸ª PG çš„ OSD å¯èƒ½æŒ‚æ‰, æˆ–è€… Mon æ²¡æœ‰æ£€æµ‹åˆ° Primary ç»Ÿè®¡ä¿¡æ¯(ç½‘ç»œæŠ–åŠ¨) |
| Undersized | PG å½“å‰ Acting Set å°äºå­˜å‚¨æ± å‰¯æœ¬æ•° |

# 3. çŠ¶æ€è¯¦è§£åŠæ•…éšœæ¨¡æ‹Ÿå¤ç°
## 3.1 Degraded
### 3.1.1 è¯´æ˜
 - é™çº§ï¼šç”±ä¸Šæ–‡å¯ä»¥å¾—çŸ¥ï¼Œæ¯ä¸ª PG æœ‰ä¸‰ä¸ªå‰¯æœ¬ï¼Œåˆ†åˆ«ä¿å­˜åœ¨ä¸åŒçš„ OSD ä¸­ï¼Œåœ¨éæ•…éšœæƒ…å†µä¸‹ï¼Œè¿™ä¸ª PG æ˜¯ active+clean çŠ¶æ€ï¼Œé‚£ä¹ˆï¼Œå¦‚æœ PG çš„ å‰¯æœ¬ osd.4 æŒ‚æ‰äº†ï¼Œè¿™ä¸ª PG æ˜¯é™çº§çŠ¶æ€ã€‚

### 3.1.2 æ•…éšœæ¨¡æ‹Ÿ
 a. åœæ­¢ osd.1
```plain
$ systemctl stop ceph-osd@1
```
b. æŸ¥çœ‹ PG çŠ¶æ€
```plain
$ bin/ceph pg stat
20 pgs: 20 active+undersized+degraded; 14512 kB data, 302 GB used, 6388 GB / 6691 GB avail; 12/36 objects degraded (33.333%)
```
c. æŸ¥çœ‹é›†ç¾¤ç›‘æ§çŠ¶æ€
```plain
$ bin/ceph health detail
HEALTH_WARN 1 osds down; Degraded data redundancy: 12/36 objects degraded (33.333%), 20 pgs unclean, 20 pgs degraded; application not enabled on 1 pool(s)
OSD_DOWN 1 osds down
    osd.1 (root=default,host=ceph-xx-cc00) is down
PG_DEGRADED Degraded data redundancy: 12/36 objects degraded (33.333%), 20 pgs unclean, 20 pgs degraded
    pg 1.0 is active+undersized+degraded, acting [0,2]
    pg 1.1 is active+undersized+degraded, acting [2,0]
```
d. å®¢æˆ·ç«¯ IO æ“ä½œ
```plain
#å†™å…¥å¯¹è±¡
$ bin/rados -p test_pool put myobject ceph.conf

#è¯»å–å¯¹è±¡åˆ°æ–‡ä»¶
$ bin/rados -p test_pool get myobject.old

#æŸ¥çœ‹æ–‡ä»¶
$ ll ceph.conf*
-rw-r--r-- 1 root root 6211 Jun 25 14:01 ceph.conf
-rw-r--r-- 1 root root 6211 Jul  3 19:57 ceph.conf.old
```

**æ•…éšœæ€»ç»“**ï¼š
ä¸ºäº†æ¨¡æ‹Ÿæ•…éšœï¼Œ(size = 3, min_size = 2) æˆ‘ä»¬æ‰‹åŠ¨åœæ­¢äº† osd.1ï¼Œç„¶åæŸ¥çœ‹ PG çŠ¶æ€ï¼Œå¯è§ï¼Œå®ƒæ­¤åˆ»çš„çŠ¶æ€æ˜¯ active+undersized+degraded,å½“ä¸€ä¸ª PG æ‰€åœ¨çš„ OSD æŒ‚æ‰ä¹‹åï¼Œè¿™ä¸ª PG å°±ä¼šè¿›å…¥ undersized+degraded çŠ¶æ€ï¼Œè€Œåé¢çš„[0,2]çš„æ„ä¹‰å°±æ˜¯è¿˜æœ‰ä¸¤ä¸ªå‰¯æœ¬å­˜æ´»åœ¨ osd.0 å’Œ osd.2 ä¸Š, å¹¶ä¸”è¿™ä¸ªæ—¶å€™å®¢æˆ·ç«¯å¯ä»¥æ­£å¸¸è¯»å†™ IOã€‚

### 3.1.3 æ€»ç»“
- é™çº§å°±æ˜¯åœ¨å‘ç”Ÿäº†ä¸€äº›æ•…éšœæ¯”å¦‚ OSD æŒ‚æ‰ä¹‹åï¼ŒCeph å°†è¿™ä¸ª OSD ä¸Šçš„æ‰€æœ‰ PG æ ‡è®°ä¸º Degradedã€‚
- é™çº§çš„é›†ç¾¤å¯ä»¥æ­£å¸¸è¯»å†™æ•°æ®ï¼Œé™çº§çš„ PG åªæ˜¯ç›¸å½“äºå°æ¯›ç—…è€Œå·²ï¼Œå¹¶ä¸æ˜¯ä¸¥é‡çš„é—®é¢˜ã€‚
- Undersized çš„æ„æ€å°±æ˜¯å½“å‰å­˜æ´»çš„ PG å‰¯æœ¬æ•°ä¸º 2ï¼Œå°äºå‰¯æœ¬æ•° 3ï¼Œå°†å…¶åšæ­¤æ ‡è®°ï¼Œè¡¨æ˜å­˜è´§å‰¯æœ¬æ•°ä¸è¶³ï¼Œä¹Ÿä¸æ˜¯ä¸¥é‡çš„é—®é¢˜ã€‚

## 3.2 Peered
### 3.2.1 è¯´æ˜
 - Peering å·²ç»å®Œæˆï¼Œä½†æ˜¯ PG å½“å‰ Acting Set è§„æ¨¡å°äºå­˜å‚¨æ± è§„å®šçš„æœ€å°å‰¯æœ¬æ•°(min_size)ã€‚

### 3.2.2 æ•…éšœæ¨¡æ‹Ÿ

a. åœæ‰ä¸¤ä¸ªå‰¯æœ¬ osd.1,osd.0
```plain
$ systemctl stop ceph-osd@1
$ systemctl stop ceph-osd@0
```
b. æŸ¥çœ‹é›†ç¾¤å¥åº·çŠ¶æ€
```plain
$ bin/ceph health detail
HEALTH_WARN 1 osds down; Reduced data availability: 4 pgs inactive; Degraded data redundancy: 26/39 objects degraded (66.667%), 20 pgs unclean, 20 pgs degraded; application not enabled on 1 pool(s)
OSD_DOWN 1 osds down
    osd.0 (root=default,host=ceph-xx-cc00) is down
PG_AVAILABILITY Reduced data availability: 4 pgs inactive
    pg 1.6 is stuck inactive for 516.741081, current state undersized+degraded+peered, last acting [2]
    pg 1.10 is stuck inactive for 516.737888, current state undersized+degraded+peered, last acting [2]
    pg 1.11 is stuck inactive for 516.737408, current state undersized+degraded+peered, last acting [2]
    pg 1.12 is stuck inactive for 516.736955, current state undersized+degraded+peered, last acting [2]
PG_DEGRADED Degraded data redundancy: 26/39 objects degraded (66.667%), 20 pgs unclean, 20 pgs degraded
    pg 1.0 is undersized+degraded+peered, acting [2]
    pg 1.1 is undersized+degraded+peered, acting [2]
```
c. å®¢æˆ·ç«¯ IO æ“ä½œ(å¤¯ä½)
```plain
#è¯»å–å¯¹è±¡åˆ°æ–‡ä»¶ï¼Œå¤¯ä½IO
$ bin/rados -p test_pool get myobject  ceph.conf.old
```
**æ•…éšœæ€»ç»“ï¼š**
- ç°åœ¨ pg åªå‰©ä¸‹ osd.2 ä¸Šå­˜æ´»ï¼Œå¹¶ä¸” pg è¿˜å¤šäº†ä¸€ä¸ªçŠ¶æ€ï¼špeeredï¼Œè‹±æ–‡çš„æ„æ€æ˜¯ä»”ç»†çœ‹ï¼Œè¿™é‡Œæˆ‘ä»¬å¯ä»¥ç†è§£æˆåå•†ã€æœç´¢ã€‚
- è¿™æ—¶å€™è¯»å–æ–‡ä»¶ï¼Œä¼šå‘ç°æŒ‡ä»¤ä¼šå¡åœ¨é‚£ä¸ªåœ°æ–¹ä¸€ç›´ä¸åŠ¨ï¼Œä¸ºä»€ä¹ˆå°±ä¸èƒ½è¯»å–å†…å®¹äº†ï¼Œå› ä¸ºæˆ‘ä»¬è®¾ç½®çš„ min_size=2 ï¼Œå¦‚æœå­˜æ´»æ•°å°‘äº 2ï¼Œæ¯”å¦‚è¿™é‡Œçš„ 1 ï¼Œé‚£ä¹ˆå°±ä¸ä¼šå“åº”å¤–éƒ¨çš„ IO è¯·æ±‚ã€‚

d. è°ƒæ•´ min_size=1 å¯ä»¥è§£å†³ IO å¤¯ä½é—®é¢˜
```plain
#è®¾ç½®min_size = 1
$ bin/ceph osd pool set test_pool min_size 1
set pool 1 min_size to 1
```
e. æŸ¥çœ‹é›†ç¾¤ç›‘æ§çŠ¶æ€
```plain
$ bin/ceph health detail
HEALTH_WARN 1 osds down; Degraded data redundancy: 26/39 objects degraded (66.667%), 20 pgs unclean, 20 pgs degraded, 20 pgs undersized; application not enabled on 1 pool(s)
OSD_DOWN 1 osds down
    osd.0 (root=default,host=ceph-xx-cc00) is down
PG_DEGRADED Degraded data redundancy: 26/39 objects degraded (66.667%), 20 pgs unclean, 20 pgs degraded, 20 pgs undersized
    pg 1.0 is stuck undersized for 65.958983, current state active+undersized+degraded, last acting [2]
    pg 1.1 is stuck undersized for 65.960092, current state active+undersized+degraded, last acting [2]
    pg 1.2 is stuck undersized for 65.960974, current state active+undersized+degraded, last acting [2]
```
f. å®¢æˆ·ç«¯ IO æ“ä½œ
```plain
#è¯»å–å¯¹è±¡åˆ°æ–‡ä»¶ä¸­
$ ll -lh ceph.conf*
-rw-r--r-- 1 root root 6.1K Jun 25 14:01 ceph.conf
-rw-r--r-- 1 root root 6.1K Jul  3 20:11 ceph.conf.old
-rw-r--r-- 1 root root 6.1K Jul  3 20:11 ceph.conf.old.1
```
**æ•…éšœæ€»ç»“ï¼š**
- å¯ä»¥çœ‹åˆ°ï¼ŒPG çŠ¶æ€ Peered æ²¡æœ‰äº†ï¼Œå¹¶ä¸”å®¢æˆ·ç«¯æ–‡ä»¶ IO å¯ä»¥æ­£å¸¸è¯»å†™äº†ã€‚
- å½“ min_size=1 æ—¶ï¼Œåªè¦é›†ç¾¤é‡Œé¢æœ‰ä¸€ä»½å‰¯æœ¬æ´»ç€ï¼Œé‚£å°±å¯ä»¥å“åº”å¤–éƒ¨çš„ IO è¯·æ±‚ã€‚

### 3.2.3 æ€»ç»“
 - Peered çŠ¶æ€æˆ‘ä»¬è¿™é‡Œå¯ä»¥å°†å®ƒç†è§£æˆå®ƒåœ¨ç­‰å¾…å…¶ä»–å‰¯æœ¬ä¸Šçº¿ã€‚
 - å½“ min_size = 2 æ—¶ï¼Œä¹Ÿå°±æ˜¯å¿…é¡»ä¿è¯æœ‰ä¸¤ä¸ªå‰¯æœ¬å­˜æ´»çš„æ—¶å€™å°±å¯ä»¥å»é™¤ Peered è¿™ä¸ªçŠ¶æ€ã€‚
 - å¤„äº Peered çŠ¶æ€çš„ PG æ˜¯ä¸èƒ½å“åº”å¤–éƒ¨çš„è¯·æ±‚çš„å¹¶ä¸” IO è¢«æŒ‚èµ·ã€‚

## 3.3 Remapped
### 3.3.1 è¯´æ˜
 - Peering å®Œæˆï¼ŒPG å½“å‰ Acting Set ä¸ Up Set ä¸ä¸€è‡´å°±ä¼šå‡ºç° Remapped çŠ¶æ€ã€‚

### 3.3.2 æ•…éšœæ¨¡æ‹Ÿ
a. åœæ­¢ osd.x
```plain
$ systemctl stop ceph-osd@x
```
b. é—´éš” 5 åˆ†é’Ÿï¼Œå¯åŠ¨ osd.x
```plain
$ systemctl start ceph-osd@x
```
c. æŸ¥çœ‹ PG çŠ¶æ€
```plain
$ ceph pg stat
1416 pgs: 6 active+clean+remapped, 1288 active+clean, 3 stale+active+clean, 119 active+undersized+degraded; 74940 MB data, 250 GB used, 185 TB / 185 TB avail; 1292/48152 objects degraded (2.683%)
$ ceph pg dump | grep remapped
dumped all
13.cd         0                  0        0         0       0         0    2        2      active+clean+remapped 2018-07-03 20:26:14.478665       9453'2   20716:11343    [10,23]         10 [10,23,14]             10       9453'2 2018-07-03 20:26:14.478597          9453'2 2018-07-01 13:11:43.262605
3.1a         44                  0        0         0       0 373293056 1500     1500      active+clean+remapped 2018-07-03 20:25:47.885366  20272'79063  20716:109173     [9,23]          9  [9,23,12]              9  20272'79063 2018-07-03 03:14:23.960537     20272'79063 2018-07-03 03:14:23.960537
5.f           0                  0        0         0       0         0    0        0      active+clean+remapped 2018-07-03 20:25:47.888430          0'0   20716:15530     [23,8]         23  [23,8,22]             23          0'0 2018-07-03 06:44:05.232179             0'0 2018-06-30 22:27:16.778466
3.4a         45                  0        0         0       0 390070272 1500     1500      active+clean+remapped 2018-07-03 20:25:47.886669  20272'78385  20716:108086     [7,23]          7  [7,23,17]              7  20272'78385 2018-07-03 13:49:08.190133      7998'78363 2018-06-28 10:30:38.201993
13.102        0                  0        0         0       0         0    5        5      active+clean+remapped 2018-07-03 20:25:47.884983       9453'5   20716:11334     [1,23]          1  [1,23,14]              1       9453'5 2018-07-02 21:10:42.028288          9453'5 2018-07-02 21:10:42.028288
13.11d        1                  0        0         0       0   4194304 1539     1539      active+clean+remapped 2018-07-03 20:25:47.886535  20343'22439   20716:86294     [4,23]          4  [4,23,15]              4  20343'22439 2018-07-03 17:21:18.567771     20343'22439 2018-07-03 17:21:18.567771#2åˆ†é’Ÿä¹‹åæŸ¥è¯¢$ ceph pg stat
1416 pgs: 2 active+undersized+degraded+remapped+backfilling, 10 active+undersized+degraded+remapped+backfill_wait, 1401 active+clean, 3 stale+active+clean; 74940 MB data, 247 GB used, 179 TB / 179 TB avail; 260/48152 objects degraded (0.540%); 49665 kB/s, 9 objects/s recovering$ ceph pg dump | grep remapped
dumped all
13.1e8 2 0 2 0 0 8388608 1527 1527 active+undersized+degraded+remapped+backfill_wait 2018-07-03 20:30:13.999637 9493'38727 20754:165663 [18,33,10] 18 [18,10] 18 9493'38727 2018-07-03 19:53:43.462188 0'0 2018-06-28 20:09:36.303126
```
d. å®¢æˆ·ç«¯ IO æ“ä½œ
```plain
#radosè¯»å†™æ­£å¸¸
rados -p test_pool put myobject /tmp/test.log
```

### 3.3.3 æ€»ç»“
- åœ¨ OSD æŒ‚æ‰æˆ–è€…åœ¨æ‰©å®¹çš„æ—¶å€™ PG ä¸Šçš„ OSD ä¼šæŒ‰ç…§ Crush ç®—æ³•é‡æ–°åˆ†é… PG æ‰€å±çš„ osd ç¼–å·ã€‚å¹¶ä¸”ä¼šæŠŠ PG  Remap åˆ°åˆ«çš„ OSD ä¸Šå»ã€‚
- Remapped çŠ¶æ€æ—¶ï¼ŒPG å½“å‰ Acting Set ä¸ Up Set ä¸ä¸€è‡´ã€‚
- å®¢æˆ·ç«¯ IO å¯ä»¥æ­£å¸¸è¯»å†™ã€‚

## 3.4 Recovery
### 3.4.1 è¯´æ˜
 - æŒ‡ PG é€šè¿‡ PGLog æ—¥å¿—é’ˆå¯¹æ•°æ®ä¸ä¸€è‡´çš„å¯¹è±¡è¿›è¡ŒåŒæ­¥å’Œä¿®å¤çš„è¿‡ç¨‹ã€‚

### 3.4.2 æ•…éšœæ¨¡æ‹Ÿ
a. åœæ­¢ osd.x
```plain
$ systemctl stop ceph-osd@x
```
b. é—´éš” 1 åˆ†é’Ÿå¯åŠ¨ osd.x
```plain
osd$ systemctl start ceph-osd@x
```
c. æŸ¥çœ‹é›†ç¾¤ç›‘æ§çŠ¶æ€
```plain
$ ceph health detail
HEALTH_WARN Degraded data redundancy: 183/57960 objects degraded (0.316%), 17 pgs unclean, 17 pgs degraded
PG_DEGRADED Degraded data redundancy: 183/57960 objects degraded (0.316%), 17 pgs unclean, 17 pgs degraded
    pg 1.19 is active+recovery_wait+degraded, acting [29,9,17]
```
### 3.4.3 æ€»ç»“
 - Recovery æ˜¯é€šè¿‡è®°å½•çš„ PGLog è¿›è¡Œæ¢å¤æ•°æ®çš„ã€‚
- è®°å½•çš„ PGLog åœ¨ osd_max_pg_log_entries=10000 æ¡ä»¥å†…ï¼Œè¿™ä¸ªæ—¶å€™é€šè¿‡ PGLog å°±èƒ½å¢é‡æ¢å¤æ•°æ®ã€‚

## 3.5 Backfill
### 3.5.1 è¯´æ˜
 - å½“ PG çš„å‰¯æœ¬æ— éé€šè¿‡ PGLog æ¥æ¢å¤æ•°æ®ï¼Œè¿™ä¸ªæ—¶å€™å°±éœ€è¦è¿›è¡Œå…¨é‡åŒæ­¥ï¼Œé€šè¿‡å®Œå…¨æ‹·è´å½“å‰ Primary æ‰€æœ‰å¯¹è±¡çš„æ–¹å¼è¿›è¡Œå…¨é‡åŒæ­¥ã€‚

### 3.5.2 æ•…éšœæ¨¡æ‹Ÿ
a. åœæ­¢ osd.x
```plain
$ systemctl stop ceph-osd@x
```
b. é—´éš” 10 åˆ†é’Ÿå¯åŠ¨ osd.x
```plain
$ osd systemctl start ceph-osd@x
```
c. æŸ¥çœ‹é›†ç¾¤å¥åº·çŠ¶æ€
```plain
$ ceph health detail
HEALTH_WARN Degraded data redundancy: 6/57927 objects degraded (0.010%), 1 pg unclean, 1 pg degraded
PG_DEGRADED Degraded data redundancy: 6/57927 objects degraded (0.010%), 1 pg unclean, 1 pg degraded
    pg 3.7f is active+undersized+degraded+remapped+backfilling, acting [21,29]
```
### 3.5.3 æ€»ç»“
 - æ— æ³•æ ¹æ®è®°å½•çš„ PGLog è¿›è¡Œæ¢å¤æ•°æ®æ—¶ï¼Œå°±éœ€è¦æ‰§è¡Œ Backfill è¿‡ç¨‹å…¨é‡æ¢å¤æ•°æ®ã€‚
 - å¦‚æœè¶…è¿‡ osd_max_pg_log_entries=10000 æ¡ï¼Œ è¿™ä¸ªæ—¶å€™éœ€è¦å…¨é‡æ¢å¤æ•°æ®ã€‚

## 3.6 Stale
### 3.6.1 è¯´æ˜
 - mon æ£€æµ‹åˆ°å½“å‰ PG çš„ Primary æ‰€åœ¨çš„ osd å®•æœºã€‚
 - Primary è¶…æ—¶æœªå‘ mon ä¸ŠæŠ¥ pg ç›¸å…³çš„ä¿¡æ¯(ä¾‹å¦‚ç½‘ç»œé˜»å¡)ã€‚
 - PG å†…ä¸‰ä¸ªå‰¯æœ¬éƒ½æŒ‚æ‰çš„æƒ…å†µã€‚

### 3.6.2 æ•…éšœæ¨¡æ‹Ÿ
a. åˆ†åˆ«åœæ­¢ PG ä¸­çš„ä¸‰ä¸ªå‰¯æœ¬ osd, é¦–å…ˆåœæ­¢ osd.23
```plain
$ systemctl stop ceph-osd@23
```
b. ç„¶ååœæ­¢ osd.24
```plain
$ systemctl stop ceph-osd@24
```
c. æŸ¥çœ‹åœæ­¢ä¸¤ä¸ªå‰¯æœ¬ PG 1.45 çš„çŠ¶æ€(undersized+degraded+peered)
```plain
$ ceph health detail
HEALTH_WARN 2 osds down; Reduced data availability: 9 pgs inactive; Degraded data redundancy: 3041/47574 objects degraded (6.392%), 149 pgs unclean, 149 pgs degraded, 149 pgs undersized
OSD_DOWN 2 osds down
    osd.23 (root=default,host=ceph-xx-osd02) is down
    osd.24 (root=default,host=ceph-xx-osd03) is down
PG_AVAILABILITY Reduced data availability: 9 pgs inactive
    pg 1.45 is stuck inactive for 281.355588, current state undersized+degraded+peered, last acting [10]
```
d. åœ¨åœæ­¢ PG 1.45 ä¸­ç¬¬ä¸‰ä¸ªå‰¯æœ¬ osd.10
```plain
$ systemctl stop ceph-osd@10
```
e. æŸ¥çœ‹åœæ­¢ä¸‰ä¸ªå‰¯æœ¬ PG 1.45 çš„çŠ¶æ€(stale+undersized+degraded+peered)
```plain
$ ceph health detail
HEALTH_WARN 3 osds down; Reduced data availability: 26 pgs inactive, 2 pgs stale; Degraded data redundancy: 4770/47574 objects degraded (10.026%), 222 pgs unclean, 222 pgs degraded, 222 pgs undersized
OSD_DOWN 3 osds down
    osd.10 (root=default,host=ceph-xx-osd01) is down
    osd.23 (root=default,host=ceph-xx-osd02) is down
    osd.24 (root=default,host=ceph-xx-osd03) is down
PG_AVAILABILITY Reduced data availability: 26 pgs inactive, 2 pgs stale
    pg 1.9 is stuck inactive for 171.200290, current state undersized+degraded+peered, last acting [13]
    pg 1.45 is stuck stale for 171.206909, current state stale+undersized+degraded+peered, last acting [10]
    pg 1.89 is stuck inactive for 435.573694, current state undersized+degraded+peered, last acting [32]
    pg 1.119 is stuck inactive for 435.574626, current state undersized+degraded+peered, last acting [28]
```
f. å®¢æˆ·ç«¯ IO æ“ä½œ
```plain
#è¯»å†™æŒ‚è½½ç£ç›˜IO å¤¯ä½
ll /mnt/
```
**æ•…éšœæ€»ç»“ï¼š**
å…ˆåœæ­¢åŒä¸€ä¸ª PG å†…ä¸¤ä¸ªå‰¯æœ¬ï¼ŒçŠ¶æ€æ˜¯ undersized+degraded+peeredã€‚
ç„¶ååœæ­¢åŒä¸€ä¸ª PG å†…ä¸‰ä¸ªå‰¯æœ¬ï¼ŒçŠ¶æ€æ˜¯ stale+undersized+degraded+peeredã€‚

### 3.6.3 æ€»ç»“
 - å½“å‡ºç°ä¸€ä¸ª PG å†…ä¸‰ä¸ªå‰¯æœ¬éƒ½æŒ‚æ‰çš„æƒ…å†µï¼Œå°±ä¼šå‡ºç° stale çŠ¶æ€ã€‚
 - æ­¤æ—¶è¯¥ PG ä¸èƒ½æä¾›å®¢æˆ·ç«¯è¯»å†™ï¼ŒIO æŒ‚èµ·å¤¯ä½ã€‚
 - Primary è¶…æ—¶æœªå‘ mon ä¸ŠæŠ¥ pg ç›¸å…³çš„ä¿¡æ¯(ä¾‹å¦‚ç½‘ç»œé˜»å¡),ä¹Ÿä¼šå‡ºç° stale çŠ¶æ€ã€‚


## 3.7 Inconsistent
### 3.7.1 è¯´æ˜
 - PG é€šè¿‡ Scrub æ£€æµ‹åˆ°æŸä¸ªæˆ–è€…æŸäº›å¯¹è±¡åœ¨ PG å®ä¾‹é—´å‡ºç°äº†ä¸ä¸€è‡´

### 3.7.2 æ•…éšœæ¨¡æ‹Ÿ
a. åˆ é™¤ PG 3.0 ä¸­å‰¯æœ¬ osd.34 å¤´æ–‡ä»¶
```plain
$ rm -rf /var/lib/ceph/osd/ceph-34/current/3.0_head/DIR_0/1000000697c.0000122c__head_19785300__3
```
b. æ‰‹åŠ¨æ‰§è¡Œ PG 3.0 è¿›è¡Œæ•°æ®æ¸…æ´—
```plain
$ ceph pg scrub 3.0
instructing pg 3.0 on osd.34 to scrub
```
c. æ£€æŸ¥é›†ç¾¤ç›‘æ§çŠ¶æ€
```plain
$ ceph health detail
HEALTH_ERR 1 scrub errors; Possible data damage: 1 pg inconsistent
OSD_SCRUB_ERRORS 1 scrub errors
PG_DAMAGED Possible data damage: 1 pg inconsistent
    pg 3.0 is active+clean+inconsistent, acting [34,23,1]
```
d. ä¿®å¤ PG 3.0
```plain
$ ceph pg repair 3.0
instructing pg 3.0 on osd.34 to repair

#æŸ¥çœ‹é›†ç¾¤ç›‘æ§çŠ¶æ€
$ ceph health detail
HEALTH_ERR 1 scrub errors; Possible data damage: 1 pg inconsistent, 1 pg repair
OSD_SCRUB_ERRORS 1 scrub errors
PG_DAMAGED Possible data damage: 1 pg inconsistent, 1 pg repair
    pg 3.0 is active+clean+scrubbing+deep+inconsistent+repair, acting [34,23,1]

#é›†ç¾¤ç›‘æ§çŠ¶æ€å·²æ¢å¤æ­£å¸¸
$ ceph health detail
HEALTH_OK
```
**æ•…éšœæ€»ç»“ï¼š**
å½“ PG å†…éƒ¨ä¸‰ä¸ªå‰¯æœ¬æœ‰æ•°æ®ä¸ä¸€è‡´çš„æƒ…å†µï¼Œæƒ³è¦ä¿®å¤ä¸ä¸€è‡´çš„æ•°æ®æ–‡ä»¶ï¼Œåªéœ€è¦æ‰§è¡Œ ceph pg repair ä¿®å¤æŒ‡ä»¤ï¼Œceph å°±ä¼šä»å…¶ä»–çš„å‰¯æœ¬ä¸­å°†ä¸¢å¤±çš„æ–‡ä»¶æ‹·è´è¿‡æ¥å°±è¡Œä¿®å¤æ•°æ®ã€‚

### 3.7.3 æ•…éšœæ¨¡æ‹Ÿ
 - å½“ osd çŸ­æš‚æŒ‚æ‰çš„æ—¶å€™ï¼Œå› ä¸ºé›†ç¾¤å†…è¿˜å­˜åœ¨ç€ä¸¤ä¸ªå‰¯æœ¬ï¼Œæ˜¯å¯ä»¥æ­£å¸¸å†™å…¥çš„ï¼Œä½†æ˜¯ osd.34 å†…çš„æ•°æ®å¹¶æ²¡æœ‰å¾—åˆ°æ›´æ–°ï¼Œè¿‡äº†ä¸€ä¼š osd.34 ä¸Šçº¿äº†ï¼Œè¿™ä¸ªæ—¶å€™ osd.34 çš„æ•°æ®æ˜¯é™ˆæ—§çš„ï¼Œå°±é€šè¿‡å…¶ä»–çš„ OSD å‘ osd.34 è¿›è¡Œæ•°æ®çš„æ¢å¤ï¼Œä½¿å…¶æ•°æ®ä¸ºæœ€æ–°çš„ï¼Œè€Œè¿™ä¸ªæ¢å¤çš„è¿‡ç¨‹ä¸­ï¼ŒPG çš„çŠ¶æ€ä¼šä» inconsistent ->recover -> clean,æœ€ç»ˆæ¢å¤æ­£å¸¸ã€‚
- è¿™æ˜¯é›†ç¾¤æ•…éšœè‡ªæ„ˆä¸€ç§åœºæ™¯ã€‚

## 3.8 Down
### 3.8.1 è¯´æ˜
 - Peering è¿‡ç¨‹ä¸­ï¼ŒPG æ£€æµ‹åˆ°æŸä¸ªä¸èƒ½è¢«è·³è¿‡çš„ Interval ä¸­(ä¾‹å¦‚è¯¥ Interval æœŸé—´ï¼ŒPG å®Œæˆäº† Peeringï¼Œå¹¶ä¸”æˆåŠŸåˆ‡æ¢è‡³ Active çŠ¶æ€ï¼Œä»è€Œæœ‰å¯èƒ½æ­£å¸¸å¤„ç†äº†æ¥è‡ªå®¢æˆ·ç«¯çš„è¯»å†™è¯·æ±‚),å½“å‰å‰©ä½™åœ¨çº¿çš„ OSD ä¸è¶³ä»¥å®Œæˆæ•°æ®ä¿®å¤.

### 3.8.2 æ•…éšœæ¨¡æ‹Ÿ
a. æŸ¥çœ‹ PG 3.7f å†…å‰¯æœ¬æ•°
```plain
$ ceph pg dump | grep ^3.7f
dumped all
3.7f         43                  0        0         0       0 494927872 1569     1569               active+clean 2018-07-05 02:52:51.512598  21315'80115  21356:111666  [5,21,29]          5  [5,21,29]              5  21315'80115 2018-07-05 02:52:51.512568      6206'80083 2018-06-29 22:51:05.831219
```
b. åœæ­¢ PG 3.7f å‰¯æœ¬ osd.21
```plain
$ systemctl stop ceph-osd@21
```
c. æŸ¥çœ‹ PG 3.7f çŠ¶æ€
```plain
$ ceph pg dump | grep ^3.7f
dumped all
3.7f         66                  0       89         0       0 591396864 1615     1615 active+undersized+degraded 2018-07-05 15:29:15.741318  21361'80161  21365:128307     [5,29]          5     [5,29]              5  21315'80115 2018-07-05 02:52:51.512568      6206'80083 2018-06-29 22:51:05.831219
```
d. å®¢æˆ·ç«¯å†™å…¥æ•°æ®ï¼Œä¸€å®šè¦ç¡®ä¿æ•°æ®å†™å…¥åˆ° PG 3.7f çš„å‰¯æœ¬ä¸­[5,29]
```plain
$ fio -filename=/mnt/xxxsssss -direct=1 -iodepth 1 -thread -rw=read -ioengine=libaio -bs=4M -size=2G -numjobs=30 -runtime=200 -group_reporting -name=read-libaio
read-libaio: (g=0): rw=read, bs=4M-4M/4M-4M/4M-4M, ioengine=libaio, iodepth=1
...
fio-2.2.8
Starting 30 threads
read-libaio: Laying out IO file(s) (1 file(s) / 2048MB)
Jobs: 5 (f=5): [_(5),R(1),_(5),R(1),_(3),R(1),_(2),R(1),_(1),R(1),_(9)] [96.5% done] [1052MB/0KB/0KB /s] [263/0/0 iops] [eta 00m:02s]                                                            s]
read-libaio: (groupid=0, jobs=30): err= 0: pid=32966: Thu Jul  5 15:35:16 2018
  read : io=61440MB, bw=1112.2MB/s, iops=278, runt= 55203msec
    slat (msec): min=18, max=418, avg=103.77, stdev=46.19
    clat (usec): min=0, max=33, avg= 2.51, stdev= 1.45
     lat (msec): min=18, max=418, avg=103.77, stdev=46.19
    clat percentiles (usec):
     |  1.00th=[    1],  5.00th=[    1], 10.00th=[    1], 20.00th=[    2],
     | 30.00th=[    2], 40.00th=[    2], 50.00th=[    2], 60.00th=[    2],
     | 70.00th=[    3], 80.00th=[    3], 90.00th=[    4], 95.00th=[    5],
     | 99.00th=[    7], 99.50th=[    8], 99.90th=[   10], 99.95th=[   14],
     | 99.99th=[   32]
    bw (KB  /s): min=15058, max=185448, per=3.48%, avg=39647.57, stdev=12643.04
    lat (usec) : 2=19.59%, 4=64.52%, 10=15.78%, 20=0.08%, 50=0.03%
  cpu          : usr=0.01%, sys=0.37%, ctx=491792, majf=0, minf=15492
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued    : total=r=15360/w=0/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0
     latency   : target=0, window=0, percentile=100.00%, depth=1
Run status group 0 (all jobs):
   READ: io=61440MB, aggrb=1112.2MB/s, minb=1112.2MB/s, maxb=1112.2MB/s, mint=55203msec, maxt=55203msec
```
e. åœæ­¢ PG 3.7f ä¸­å‰¯æœ¬ osd.29,å¹¶ä¸”æŸ¥çœ‹ PG 3.7f çŠ¶æ€(undersized+degraded+peered)
```plain
#åœæ­¢è¯¥PGå‰¯æœ¬osd.29
systemctl stop ceph-osd@29

#æŸ¥çœ‹è¯¥PG 3.7fçŠ¶æ€ä¸ºundersized+degraded+peered
ceph pg dump | grep ^3.7f
dumped all
3.7f         70                  0      140         0       0 608174080 1623     1623 undersized+degraded+peered 2018-07-05 15:35:51.629636  21365'80169  21367:132165        [5]          5        [5]              5  21315'80115 2018-07-05 02:52:51.512568      6206'80083 2018-06-29 22:51:05.831219
```
f. åœæ­¢ PG 3.7f ä¸­å‰¯æœ¬ osd.5,å¹¶ä¸”æŸ¥çœ‹ PG 3.7f çŠ¶æ€(undersized+degraded+peered)
```plain
#åœæ­¢è¯¥PGå‰¯æœ¬osd.5
$ systemctl stop ceph-osd@5

#æŸ¥çœ‹è¯¥PGçŠ¶æ€undersized+degraded+peered
$ ceph pg dump | grep ^3.7f
dumped all
3.7f         70                  0      140         0       0 608174080 1623     1623 stale+undersized+degraded+peered 2018-07-05 15:35:51.629636  21365'80169  21367:132165        [5]          5        [5]              5  21315'80115 2018-07-05 02:52:51.512568      6206'80083 2018-06-29 22:51:05.831219
```
g. æ‹‰èµ· PG 3.7f ä¸­å‰¯æœ¬ osd.21(æ­¤æ—¶çš„ osd.21 æ•°æ®æ¯”è¾ƒé™ˆæ—§), æŸ¥çœ‹ PG çŠ¶æ€(down)
```plain
#æ‹‰èµ·è¯¥PGçš„osd.21
$ systemctl start ceph-osd@21

#æŸ¥çœ‹è¯¥PGçš„çŠ¶æ€down
$ ceph pg dump | grep ^3.7f
dumped all
3.7f         66                  0        0         0       0 591396864 1548     1548                          down 2018-07-05 15:36:38.365500  21361'80161  21370:111729       [21]         21       [21]             21  21315'80115 2018-07-05 02:52:51.512568      6206'80083 2018-06-29 22:51:05.831219
```
h. å®¢æˆ·ç«¯ IO æ“ä½œ
```plain
#æ­¤æ—¶å®¢æˆ·ç«¯IOéƒ½ä¼šå¤¯ä½
ll /mnt/
```
**æ•…éšœæ€»ç»“ï¼š**
é¦–å…ˆæœ‰ä¸€ä¸ª PG 3.7f æœ‰ä¸‰ä¸ªå‰¯æœ¬[5,21,29]ï¼Œ å½“åœæ‰ä¸€ä¸ª osd.21 ä¹‹åï¼Œ å†™å…¥æ•°æ®åˆ° osd.5, osd.29ã€‚ è¿™ä¸ªæ—¶å€™åœæ‰ osd.29, osd.5 ï¼Œæœ€åæ‹‰èµ· osd.21ã€‚ è¿™ä¸ªæ—¶å€™ osd.21 çš„æ•°æ®æ¯”è¾ƒæ—§ï¼Œå°±ä¼šå‡ºç° PG ä¸º down çš„æƒ…å†µï¼Œè¿™ä¸ªæ—¶å€™å®¢æˆ·ç«¯ IO ä¼šå¤¯ä½ï¼Œåªèƒ½æ‹‰èµ·æŒ‚æ‰çš„ osd æ‰èƒ½ä¿®å¤é—®é¢˜ã€‚

### 3.8.3 PG ä¸º Down çš„ OSD ä¸¢å¤±æˆ–æ— æ³•æ‹‰èµ·
  - ä¿®å¤æ–¹å¼(ç”Ÿäº§ç¯å¢ƒå·²éªŒè¯)
```plain
      a. åˆ é™¤æ— æ³•æ‹‰èµ·çš„OSD
      b. åˆ›å»ºå¯¹åº”ç¼–å·çš„OSD
      c. PGçš„DownçŠ¶æ€å°±ä¼šæ¶ˆå¤±
      d. å¯¹äºunfound çš„PG ï¼Œå¯ä»¥é€‰æ‹©deleteæˆ–è€…revert
         ceph pg {pg-id} mark_unfound_lost revert|delete
```
### 3.8.4 ç»“è®º
  - å…¸å‹çš„åœºæ™¯ï¼šA(ä¸»)ã€Bã€C
```plain
      a. é¦–å…ˆkill B
      b. æ–°å†™å…¥æ•°æ®åˆ° Aã€C
      c. kill Aå’ŒC
      d. æ‹‰èµ·B
```
 - å‡ºç° PG ä¸º Down çš„åœºæ™¯æ˜¯ç”±äº osd èŠ‚ç‚¹æ•°æ®å¤ªæ—§ï¼Œå¹¶ä¸”å…¶ä»–åœ¨çº¿çš„ osd ä¸è¶³ä»¥å®Œæˆæ•°æ®ä¿®å¤ã€‚
 - è¿™ä¸ªæ—¶å€™è¯¥ PG ä¸èƒ½æä¾›å®¢æˆ·ç«¯ IO è¯»å†™ï¼Œ IO ä¼šæŒ‚èµ·å¤¯ä½ã€‚

## 3.9 Incomplete
Peering è¿‡ç¨‹ä¸­ï¼Œ ç”±äº a. æ— éé€‰å‡ºæƒå¨æ—¥å¿— b. é€šè¿‡ choose_acting é€‰å‡ºçš„ Acting Set åç»­ä¸è¶³ä»¥å®Œæˆæ•°æ®ä¿®å¤ï¼Œå¯¼è‡´ Peering æ— éæ­£å¸¸å®Œæˆã€‚
å¸¸è§äº ceph é›†ç¾¤åœ¨ peering çŠ¶æ€ä¸‹ï¼Œæ¥å›é‡å¯æœåŠ¡å™¨ï¼Œæˆ–è€…æ‰ç”µã€‚

### 3.9.1 æ€»ç»“
 - ä¿®å¤æ–¹å¼ [wanted: command to clear 'incomplete' PGs](http://tracker.ceph.com/issues/10098)
æ¯”å¦‚ï¼špg 1.1 æ˜¯ incompleteï¼Œå…ˆå¯¹æ¯” pg 1.1 çš„ä¸»å‰¯æœ¬ä¹‹é—´ pg é‡Œé¢çš„å¯¹è±¡æ•° å“ªä¸ªå¯¹è±¡æ•°å¤š å°±æŠŠå“ªä¸ª pg export å‡ºæ¥
ç„¶å import åˆ°å¯¹è±¡æ•°å°‘çš„ pg é‡Œé¢ ç„¶åå† mark completeï¼Œä¸€å®šè¦å…ˆ export pg å¤‡ä»½ã€‚

**ç®€å•æ–¹å¼ï¼Œæ•°æ®å¯èƒ½åˆä¸¢çš„æƒ…å†µ**
```plain
   a. stop the osd that is primary for the incomplete PG;
   b. run: ceph-objectstore-tool --data-path ... --journal-path ... --pgid $PGID --op mark-complete
   c. start the osd.
```

**ä¿è¯æ•°æ®å®Œæ•´æ€§**
```plain
#1. æŸ¥çœ‹pg 1.1ä¸»å‰¯æœ¬é‡Œé¢çš„å¯¹è±¡æ•°ï¼Œå‡è®¾ä¸»æœ¬å¯¹è±¡æ•°å¤šï¼Œåˆ™åˆ°ä¸»æœ¬æ‰€åœ¨osdèŠ‚ç‚¹æ‰§è¡Œ
$ ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-0/ --journal-path /var/lib/ceph/osd/ceph-0/journal --pgid 1.1 --op export --file /home/pg1.1

#2. ç„¶åå°†/home/pg1.1 scpåˆ°å‰¯æœ¬æ‰€åœ¨èŠ‚ç‚¹ï¼ˆæœ‰å¤šä¸ªå‰¯æœ¬ï¼Œæ¯ä¸ªå‰¯æœ¬éƒ½è¦è¿™ä¹ˆæ“ä½œï¼‰ï¼Œç„¶ååˆ°å‰¯æœ¬æ‰€åœ¨èŠ‚ç‚¹æ‰§è¡Œ
$ ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-1/ --journal-path /var/lib/ceph/osd/ceph-1/journal --pgid 1.1 --op import --file /home/pg1.1

#3. ç„¶åå†makr complete
$ ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-1/ --journal-path /var/lib/ceph/osd/ceph-1/journal --pgid 1.1 --op mark-complete

#4. æœ€åå¯åŠ¨osd
$ start osd
```



# ä½œè€…ä¿¡æ¯
**ä½œè€…ï¼š**æèˆª
**ä¸ªäººç®€ä»‹ï¼š** å¤šå¹´çš„åº•å±‚å¼€å‘ç»éªŒï¼Œåœ¨é«˜æ€§èƒ½ nginx å¼€å‘å’Œåˆ†å¸ƒå¼ç¼“å­˜ redis cluster æœ‰ç€ä¸°å¯Œçš„ç»éªŒï¼Œç›®å‰ä»äº‹ Ceph å·¥ä½œä¸¤å¹´å·¦å³ã€‚
å…ˆååœ¨ 58 åŒåŸã€æ±½è½¦ä¹‹å®¶ã€ä¼˜é…·åœŸè±†é›†å›¢å·¥ä½œã€‚
ç›®å‰ä¾›èŒäºæ»´æ»´åŸºç¡€å¹³å°è¿ç»´éƒ¨-æŠ€æœ¯ä¸“å®¶å²—ä½   è´Ÿè´£åˆ†å¸ƒå¼ Ceph é›†ç¾¤å¼€å‘åŠè¿ç»´ç­‰å·¥ä½œã€‚
ä¸ªäººä¸»è¦å…³æ³¨çš„æŠ€æœ¯é¢†åŸŸï¼šé«˜æ€§èƒ½ Nginx å¼€å‘ã€åˆ†å¸ƒå¼ç¼“å­˜ã€åˆ†å¸ƒå¼å­˜å‚¨ã€‚
