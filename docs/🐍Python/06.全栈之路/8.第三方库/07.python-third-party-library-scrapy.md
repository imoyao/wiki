---
title: Python å…¨æ ˆä¹‹è·¯ç³»åˆ—ä¹‹ scrapy çˆ¬è™«

tags: 
  - ç¼–ç 
  - scrapy
  - çˆ¬è™«
top: 7
categories: 
  - ğŸ’»å·¥ä½œ
  - ğŸPython
  - å…¨æ ˆä¹‹è·¯
  - ç¬¬ä¸‰æ–¹åº“
date: 2020-05-23 18:21:46
permalink: /pylibs/scrapy/
---

> An open source and collaborative framework for extracting the data you need from websites.

å®˜ç½‘ï¼šhttps://scrapy.org
GITHUB åœ°å€ï¼šhttps://github.com/scrapy/scrapy

Scrapy è¿è¡Œæµç¨‹å¤§æ¦‚å¦‚ä¸‹ï¼š

1. å¼•æ“ä»è°ƒåº¦å™¨ä¸­å–å‡ºä¸€ä¸ªé“¾æ¥(URL)ç”¨äºæ¥ä¸‹æ¥çš„æŠ“å–
2. å¼•æ“æŠŠ URL å°è£…æˆä¸€ä¸ªè¯·æ±‚(Request)ä¼ ç»™ä¸‹è½½å™¨
3. ä¸‹è½½å™¨æŠŠèµ„æºä¸‹è½½ä¸‹æ¥ï¼Œå¹¶å°è£…æˆåº”ç­”åŒ…(Response)
4. çˆ¬è™«è§£æ Response
5. è§£æå‡ºå®ä½“ï¼ˆItemï¼‰,åˆ™äº¤ç»™å®ä½“ç®¡é“è¿›è¡Œè¿›ä¸€æ­¥çš„å¤„ç†
6. è§£æå‡ºçš„æ˜¯é“¾æ¥ï¼ˆURLï¼‰,åˆ™æŠŠ URL äº¤ç»™è°ƒåº¦å™¨ç­‰å¾…æŠ“å–

## å®‰è£…

å› ä¸ºæˆ‘æ˜¯ Ubuntu ç³»ç»Ÿï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥é€šè¿‡ pip å®‰è£… scrapy

```bash
pip install scrapy
```

## ä½¿ç”¨

åˆ›å»ºé¡¹ç›®

```bash
scrapy startproject xiaohuar
```

ç›®å½•ç»“æ„

```bash
â‡’  tree xiaohuawang 
xiaohuawang
# é¡¹ç›®çš„é…ç½®ä¿¡æ¯ï¼Œä¸»è¦ä¸ºScrapyå‘½ä»¤è¡Œå·¥å…·æä¾›ä¸€ä¸ªåŸºç¡€çš„é…ç½®ä¿¡æ¯ã€‚ï¼ˆçœŸæ­£çˆ¬è™«ç›¸å…³çš„é…ç½®ä¿¡æ¯åœ¨settings.pyæ–‡ä»¶ä¸­ï¼‰
â”œâ”€â”€ scrapy.cfg
â””â”€â”€ xiaohuawang
    â”œâ”€â”€ __init__.py
    # è®¾ç½®æ•°æ®å­˜å‚¨æ¨¡æ¿ï¼Œç”¨äºç»“æ„åŒ–æ•°æ®
    â”œâ”€â”€ items.py
    # æ•°æ®å¤„ç†è¡Œä¸ºï¼Œå¦‚ï¼šä¸€èˆ¬ç»“æ„åŒ–çš„æ•°æ®æŒä¹…åŒ–
    â”œâ”€â”€ pipelines.py
    â”œâ”€â”€ __pycache__
    # é…ç½®æ–‡ä»¶ï¼Œå¦‚ï¼šé€’å½’çš„å±‚æ•°ã€å¹¶å‘æ•°ï¼Œå»¶è¿Ÿä¸‹è½½ç­‰
    â”œâ”€â”€ settings.py
    # çˆ¬è™«ç›®å½•ï¼Œå¦‚ï¼šåˆ›å»ºæ–‡ä»¶ï¼Œç¼–å†™çˆ¬è™«è§„åˆ™
    â””â”€â”€ spiders
        â”œâ”€â”€ __init__.py
        â””â”€â”€ __pycache__

4 directories, 6 files
```

ç¼–å†™çˆ¬è™«

åˆ›å»ºæ–‡ä»¶ï¼š"xiaohuar/xiaohuar/spiders/myspider.py"

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
import scrapy

class XiaoHuarSpider(scrapy.spiders.Spider):
    name = "xiaohuar"  # APPçš„åå­—ï¼Œå¿…é¡»å®šä¹‰
    start_urls = [
        "http://www.xiaohuar.com/hua/",  # èµ·å§‹URL
    ]

    def parse(self, response):  # æŠ“å–start_urlsé¡µé¢ï¼Œè‡ªåŠ¨æ‰§è¡Œparseå›è°ƒå‡½æ•°
        current_url = response.url  # å½“å‰è¯·æ±‚çš„URL
        body = response.body  # è¯·æ±‚çš„å†…å®¹
        unicode_body = response.body_as_unicode()  # ç¼–ç 
        print(body)
```

è¿è¡Œ

è¿›å…¥ xiaohuar ç›®å½•ï¼Œè¿è¡Œå‘½ä»¤

```bash
scrapy runspider myspider.py --nolog  # ä¸è¾“å‡ºdebugæ—¥å¿—
```

ä¸€ä¸ªæŠ“å–å›¾ç‰‡çš„å°å®ä¾‹

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
import scrapy
import os
import urllib
from scrapy.selector import HtmlXPathSelector


class XiaoHuarSpider(scrapy.spiders.Spider):
    name = "xiaohuar"  # APPçš„åå­—ï¼Œå¿…é¡»å®šä¹‰
    start_urls = [
        "http://www.xiaohuar.com/hua/",  # èµ·å§‹URL
    ]

    def parse(self, response):  # æŠ“å–start_urlsé¡µé¢ï¼Œè‡ªåŠ¨æ‰§è¡Œparseå›è°ƒå‡½æ•°
        hxs = HtmlXPathSelector(response)  # åŒ¹é…æŸ¥æ‰¾
        items = hxs.select('//div[@class="item_list infinite_scroll"]/div')
        for i in range(len(items)):
            srcs = hxs.select(
                '//div[@class="item_list infinite_scroll"]/div[%d]//div[@class="img"]/a/img/@src' % i).extract()
            names = hxs.select(
                '//div[@class="item_list infinite_scroll"]/div[%d]//div[@class="img"]/span/text()' % i).extract()
            schools = hxs.select(
                '//div[@class="item_list infinite_scroll"]/div[%d]//div[@class="img"]/div[@class="btns"]/a/text()' % i).extract()
            if srcs and names and schools:
                # print(names, srcs, schools)
                # ['è¦ƒç½—è¹'] ['/d/file/20161018/5385b7113046ac9ae560da41a44b12af.jpg'] ['å¹¿è¥¿å†œä¸šèŒä¸šæŠ€æœ¯å­¦é™¢']
                try:
                    ab_src = "http://www.xiaohuar.com" + srcs[0]  # æ–‡ä»¶è·¯å¾„
                    file_name = names[0] + "." + srcs[0].split(".")[-1]  # ä¿å­˜çš„æ–‡ä»¶å
                    file_path = os.path.join("./pic", file_name)  # ä¿å­˜çš„è·¯å¾„
                    # print(ab_src, file_name, file_path)
                    # http://www.xiaohuar.com/d/file/20161018/5385b7113046ac9ae560da41a44b12af.jpg è¦ƒç½—è¹jpg ./pic/è¦ƒç½—è¹jpg
                    urllib.request.urlretrieve(ab_src, file_path)  # ä¸‹è½½æ–‡ä»¶
                except Exception as e:
                    print("é”™è¯¯ã€‹ã€‹", e)
```

## é€‰æ‹©å™¨

åŸºæœ¬çš„é€‰æ‹©å™¨

|é€‰æ‹©å™¨|æè¿°|
|:--|:--|
|`//`|å­å­å­™å­™|
|`/`|å­©å­|
|`//div[@class="c1"][@id='i1']`|å±æ€§é€‰æ‹©å™¨|
|`//div//img/@src`|div ä¸‹æ‰€æœ‰çš„ img å±æ€§ src|
|`//div//a[1]`|ç´¢å¼•å–å€¼|
|`//div//a[1]//text()`|ç´¢å¼•å–å€¼çš„å†…å®¹|

é€šè¿‡ extract è·å–çœŸå®çš„æ•°æ®ï¼š

```python
//div[@class="c1"][@id='i1'].extract()
```

æ”¯æŒæ­£åˆ™

|é€‰æ‹©å™¨|æè¿°|
|:--|:--|
|`//.select("div//a[1]").re("æ˜µç§°:(\w+)")`|æ­£åˆ™|

å®˜æ–¹æ–‡æ¡£ï¼šhttp://scrapy-chs.readthedocs.io/zh_CN/latest/topics/selectors.html

ä¸¤ç§æŸ¥æ‰¾æ–¹å¼

```python
# å³å°†è¢«åºŸå¼ƒçš„
from scrapy.selector import HtmlXPathSelector
hxs = HtmlXPathSelector(response)
items_HtmlXPathSelector = hxs.select('//div[@class="item_list infinite_scroll"]/div')
print(len(items_HtmlXPathSelector))

from scrapy.selector import Selector
items_Selector = Selector(response=response).xpath('//div[@class="item_list infinite_scroll"]/div')
print(len(items_Selector))
```

æ­£åˆ™è¡¨è¾¾å¼å®ä¾‹

```html
<body>
    <li class="item-"><a href="link.html">first item</a></li>
    <li class="item-0"><a href="link1.html">first item</a></li>
    <li class="item-1"><a href="link2.html">second item</a></li>
</body>
```
```python
ret = Selector(response=response).xpath('//li[re:test(@class, "item-\d*")]//@href').extract()
# re -- é€šè¿‡æ­£åˆ™è¿›è¡ŒåŒ¹é…
# test -- åŒ¹é…
```

## æ‰©å±•

é‡å¤çš„ URL ä¸è®¿é—®

å…ˆæŠŠé•¿çš„ URL è¿›è¡Œ MD5 åŠ å¯†ï¼ŒåŠ å¯†æˆ 32 æˆ–è€… 64 ä½ï¼Œå¯ä»¥ä¿å­˜åœ¨ä¸€ä¸ªé›†åˆæˆ–è€…ç¼“å­˜ã€æ•°æ®åº“ä¸­ï¼Œæ¯æ¬¡æŠ“å–ä¹‹å‰éƒ½å…ˆåˆ¤æ–­æœ‰æ²¡æœ‰è¿™ä¸ª URLã€‚

é€’å½’æŸ¥æ‰¾

![scrapy-level](https://ansheng.me/wp-content/uploads/2016/12/1483065549.png)

è®¾ç½®æŸ¥æ‰¾æ·±åº¦ï¼šä¿®æ”¹`settings.py`é…ç½®æ–‡ä»¶ï¼ŒåŠ å…¥ä»¥ä¸‹å‚æ•°æŒ‡å®šæ·±åº¦`DEPTH_LIMIT = 1`

å†…å®¹æ ¼å¼åŒ–

å°±æ˜¯ç›¸å½“äºåˆ†ç±»ï¼Œæ¯”å¦‚è¯´ä¸‹é¢çš„æ–‡ä»¶ï¼š

|æ–‡ä»¶|åŠŸèƒ½|
|:--|:--|
|`myspider.py`|æŸ¥æ‰¾ URL çš„è§„åˆ™|
|`items.py`|æ•°æ®|
|`pipelines.py`|æ•°æ®æŒä¹…åŒ–|

å¦‚å›¾æ‰€ç¤ºï¼š

![scrapy-format](https://ansheng.me/wp-content/uploads/2016/12/1483065578.png)